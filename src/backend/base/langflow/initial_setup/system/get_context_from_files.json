{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FileID",
            "id": "FileID-z6JdM",
            "name": "file",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "files_ids",
            "id": "GetFile-getAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FileID-z6JdM{œdataTypeœ:œFileIDœ,œidœ:œFileID-z6JdMœ,œnameœ:œfileœ,œoutput_typesœ:[œMessageœ]}-GetFile-getAm{œfieldNameœ:œfiles_idsœ,œidœ:œGetFile-getAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FileID-z6JdM",
        "sourceHandle": "{œdataTypeœ:œFileIDœ,œidœ:œFileID-z6JdMœ,œnameœ:œfileœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GetFile-getAm",
        "targetHandle": "{œfieldNameœ:œfiles_idsœ,œidœ:œGetFile-getAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UserQuestion",
            "id": "UserQuestion-wMrl9",
            "name": "question",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "DocSpaceQdrantVectorStoreComponent-XcFyR",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-UserQuestion-wMrl9{œdataTypeœ:œUserQuestionœ,œidœ:œUserQuestion-wMrl9œ,œnameœ:œquestionœ,œoutput_typesœ:[œMessageœ]}-DocSpaceQdrantVectorStoreComponent-XcFyR{œfieldNameœ:œquestionœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "UserQuestion-wMrl9",
        "sourceHandle": "{œdataTypeœ:œUserQuestionœ,œidœ:œUserQuestion-wMrl9œ,œnameœ:œquestionœ,œoutput_typesœ:[œMessageœ]}",
        "target": "DocSpaceQdrantVectorStoreComponent-XcFyR",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-TIJdh",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "DocSpaceQdrantVectorStoreComponent-XcFyR",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-TIJdh{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-TIJdhœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-DocSpaceQdrantVectorStoreComponent-XcFyR{œfieldNameœ:œembeddingœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIEmbeddings-TIJdh",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-TIJdhœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "DocSpaceQdrantVectorStoreComponent-XcFyR",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GetFile",
            "id": "GetFile-getAm",
            "name": "files",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "files",
            "id": "DocSpaceQdrantVectorStoreComponent-XcFyR",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__GetFile-getAm{œdataTypeœ:œGetFileœ,œidœ:œGetFile-getAmœ,œnameœ:œfilesœ,œoutput_typesœ:[œDataœ]}-DocSpaceQdrantVectorStoreComponent-XcFyR{œfieldNameœ:œfilesœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "GetFile-getAm",
        "sourceHandle": "{œdataTypeœ:œGetFileœ,œidœ:œGetFile-getAmœ,œnameœ:œfilesœ,œoutput_typesœ:[œDataœ]}",
        "target": "DocSpaceQdrantVectorStoreComponent-XcFyR",
        "targetHandle": "{œfieldNameœ:œfilesœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DocSpaceQdrantVectorStoreComponent",
            "id": "DocSpaceQdrantVectorStoreComponent-XcFyR",
            "name": "search",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent1-GXz5a",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__DocSpaceQdrantVectorStoreComponent-XcFyR{œdataTypeœ:œDocSpaceQdrantVectorStoreComponentœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œnameœ:œsearchœ,œoutput_typesœ:[œMessageœ]}-CustomComponent1-GXz5a{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent1-GXz5aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "DocSpaceQdrantVectorStoreComponent-XcFyR",
        "sourceHandle": "{œdataTypeœ:œDocSpaceQdrantVectorStoreComponentœ,œidœ:œDocSpaceQdrantVectorStoreComponent-XcFyRœ,œnameœ:œsearchœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent1-GXz5a",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent1-GXz5aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent1",
            "id": "CustomComponent1-GXz5a",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-t2HjL",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent1-GXz5a{œdataTypeœ:œCustomComponent1œ,œidœ:œCustomComponent1-GXz5aœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-t2HjL{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-t2HjLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent1-GXz5a",
        "sourceHandle": "{œdataTypeœ:œCustomComponent1œ,œidœ:œCustomComponent1-GXz5aœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-t2HjL",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-t2HjLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "CustomComponent1-GXz5a",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Use as a template to create your own component.",
            "display_name": "Custom Component",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "code",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "hidden": null,
                "method": "build_output",
                "name": "output",
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema import Message\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"code\"\n    name = \"CustomComponent1\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"This is a custom component Input\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Message:\n        data = self.input_value.data.get('docs', [])\n        \n        return Message(text=\"\\n\".join(f'{item.metadata.get('id')}:{item.metadata.get('title')}\\n{item.page_content}\\n\\n' for item in data))\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input Value",
                "dynamic": false,
                "info": "This is a custom component Input",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CustomComponent1"
        },
        "dragging": false,
        "id": "CustomComponent1-GXz5a",
        "measured": {
          "height": 249,
          "width": 320
        },
        "position": {
          "x": 901.3579992903756,
          "y": 854.9591783228261
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GetFile-getAm",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves detailed file information from DocSpace including metadata, permissions, and file properties",
            "display_name": "Get File Info",
            "documentation": "",
            "edited": false,
            "field_order": [
              "files_ids",
              "asc_auth_key",
              "files_host"
            ],
            "frozen": false,
            "icon": "file-info",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Files",
                "method": "get_files",
                "name": "files",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asc_auth_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Auth key",
                "dynamic": false,
                "info": "Auth key to use",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "asc_auth_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "asc_auth_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import MessageInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data, Message\n\n\nclass GetFilesInfoComponent(Component):\n    \"\"\"Component for retrieving file information from DocSpace via API.\"\"\"\n\n\n    display_name: str = \"Get File Info\"\n    description: str = \"Retrieves detailed file information from DocSpace including metadata, permissions, and file properties\"\n    name: str = \"GetFile\"\n    icon = \"file-info\"\n\n    inputs = [\n        MessageInput(\n            name=\"files_ids\",\n            display_name=\"Files IDs\",\n            info=\"IDs of the files to get\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"asc_auth_key\",\n            display_name=\"Auth key\",\n            info=\"Auth key to use\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"files_host\",\n            display_name=\"Files Service\",\n            info=\"URL of the files service\",\n            required=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            name=\"files\",\n            display_name=\"Files\",\n            method=\"get_files\",\n        ),\n    ]\n\n    async def get_file(self, session: aiohttp.ClientSession, file_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Make an async API request to get a file.\n\n        Args:\n            session: aiohttp client session\n            file_id: ID of the file to get\n\n        Returns:\n            Dict containing the file information\n        \"\"\"\n        try:\n            headers = {\n                'Authorization': self.asc_auth_key,\n            }\n\n            files_host = self.files_host.text\n            url = f'{files_host}/api/2.0/files/file/{file_id}'\n\n            async with session.get(url, headers=headers, timeout=30) as response:\n                response.raise_for_status()\n                data = await response.json()\n                return data[\"response\"]\n\n        except Exception as e:\n            print(f\"Error getting file {file_id}: {str(e)}\")\n            return None\n\n    async def fetch_all_files(self, file_ids: List[str]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Fetch all files concurrently using aiohttp.\n\n        Args:\n            file_ids: List of file IDs to fetch\n\n        Returns:\n            List of file information dictionaries\n        \"\"\"\n        async with aiohttp.ClientSession() as session:\n            # Create tasks for all file fetches\n            tasks = [self.get_file(session, file_id) for file_id in file_ids]\n            # Wait for all tasks to complete (like Promise.all)\n            results = await asyncio.gather(*tasks)\n            # Filter out None results (failed requests)\n            return [r for r in results if r is not None]\n\n    async def get_files(self) -> Data:\n        \"\"\"\n        Make concurrent API requests to get multiple files.\n\n        Returns:\n            Data object containing list of file information\n        \"\"\"\n        try:\n            # Get file IDs from input data\n            files_data: List[str] = self.files_ids.data.get(\"files_ids\", [])\n            if not files_data:\n                return Data(data={\"files\": []})\n\n            # Fetch all files concurrently\n            files_info = await self.fetch_all_files(files_data)\n            return Data(data={\"files\": files_info})\n\n        except Exception as e:\n            return Data(data={\"files\": []})\n"
              },
              "files_host": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Files Service",
                "dynamic": false,
                "info": "URL of the files service",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "files_host",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://onlyoffice-router:8092"
              },
              "files_ids": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Files IDs",
                "dynamic": false,
                "info": "IDs of the files to get",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "files_ids",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GetFile"
        },
        "dragging": false,
        "id": "GetFile-getAm",
        "measured": {
          "height": 433,
          "width": 320
        },
        "position": {
          "x": -206.0981011455748,
          "y": 393.875814495539
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FileID-z6JdM",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Enter file ID to start vectorize.",
            "display_name": "File id",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": null,
                "method": "file_id",
                "name": "file",
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"File id\"\n    description = \"Enter file ID to start vectorize.\"\n    icon = \"type\"\n    name = \"FileID\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"File id\",\n            info=\"File id for start flow.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"file\", method=\"file_id\"),\n    ]\n\n    def file_id(self) -> Message:\n        files = self.input_value\n        \n        files_list= files.split(\",\")\n        \n        return Message(\n            text=\"Start flow\",\n            data={'files_ids': files_list},\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "File id",
                "dynamic": false,
                "info": "File id for start flow.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "5"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FileID"
        },
        "dragging": false,
        "id": "FileID-z6JdM",
        "measured": {
          "height": 229,
          "width": 320
        },
        "position": {
          "x": -672.98027474764,
          "y": 366.40166408782477
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UserQuestion-wMrl9",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Component for entering a question to search documents or query information.",
            "display_name": "User Question",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "message-circle",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Question Message",
                "hidden": null,
                "method": "create_question_message",
                "name": "question",
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass QuestionInputComponent(TextComponent):\n    display_name = \"User Question\"\n    description = \"Component for entering a question to search documents or query information.\"\n    icon = \"message-circle\"\n    name = \"UserQuestion\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Question\",\n            info=\"Enter your question to search for relevant information in documents.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Question Message\", name=\"question\", method=\"create_question_message\"),\n    ]\n\n    def create_question_message(self) -> Message:\n        \"\"\"\n        Creates a Message object containing the user's question.\n        \n        Returns:\n            Message: A message containing the user's question.\n        \"\"\"\n        question = self.input_value.strip()\n        \n        if not question:\n            return Message(\n                text=\"\",\n                data={\"empty_question\": True}\n            )\n        \n        return Message(\n            text=question,\n            data={\"question\": question}\n        )"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Question",
                "dynamic": false,
                "info": "Enter your question to search for relevant information in documents.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Write summary"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "UserQuestion"
        },
        "dragging": false,
        "id": "UserQuestion-wMrl9",
        "measured": {
          "height": 249,
          "width": 320
        },
        "position": {
          "x": -227.4623297606814,
          "y": -7.182938769589462
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DocSpaceQdrantVectorStoreComponent-XcFyR",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Add documents to Qdrant Vector Store",
            "display_name": "DocsSpace Qdrant Vector Store",
            "documentation": "",
            "edited": false,
            "field_order": [
              "collection_name",
              "question",
              "restart_search",
              "qdrant_host",
              "qdrant_port",
              "documents",
              "files",
              "metadata",
              "embedding"
            ],
            "frozen": false,
            "icon": "Qdrant",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Vectorize",
                "method": "vectorize_documents",
                "name": "vectorize",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search",
                "method": "search_documents",
                "name": "search",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Check document",
                "method": "check_document",
                "name": "check",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nfrom typing import Any, Dict, List\nfrom langchain.embeddings.base import Embeddings\nfrom langchain_community.vectorstores import Qdrant\nfrom langchain_core.documents import Document\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import Distance, VectorParams, Filter\nfrom langflow.custom import Component\nfrom langflow.schema import Message\nfrom langflow.io import (\n    MessageInput,\n    DataInput,\n    HandleInput,\n    Output,\n)\n\n\nclass DocSpaceQdrantVectorStoreComponent(Component):\n    display_name = \"DocsSpace Qdrant Vector Store\"\n    description = \"Add documents to Qdrant Vector Store\"\n    icon = \"Qdrant\"\n\n    inputs = [\n        MessageInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            required=True\n        ),\n        MessageInput(\n            name=\"question\",\n            display_name=\"Question\",\n        ),\n        MessageInput(\n            name=\"restart_search\",\n            display_name=\"Restart Search\",\n        ),\n        MessageInput(\n            name=\"qdrant_host\",\n            display_name=\"Qdrant Host\",\n        ),\n        MessageInput(\n            name=\"qdrant_port\",\n            display_name=\"Qdrant Port\",\n        ),\n\n        DataInput(\n            name=\"documents\",\n            display_name=\"Documents\",\n            list=True,\n        ),\n        DataInput(\n            name=\"files\",\n            display_name=\"Files\"\n        ),\n        DataInput(\n            name='metadata',\n            display_name=\"Metadata\"\n        ),\n\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"]\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"vectorize\",\n               display_name=\"Vectorize\",\n               method=\"vectorize_documents\"),\n        Output(name=\"search\",\n               display_name=\"Search\",\n               method=\"search_documents\"),\n        Output(name=\"check\",\n               display_name=\"Check document\",\n               method=\"check_document\")\n    ]\n\n    def check_collection_exists(self, client: QdrantClient, collection_name: str) -> bool:\n        \"\"\"Check if collection exists in Qdrant.\"\"\"\n        try:\n            collections = client.get_collections()\n            return any(collection.name == collection_name for collection in collections.collections)\n        except Exception as e:\n            raise Exception(f\"Error checking collections list: {str(e)}\")\n\n    def create_collection(self, client: QdrantClient, collection_name: str, vector_size: int) -> bool:\n        \"\"\"Create a new collection in Qdrant.\"\"\"\n        try:\n            # Create new collection\n            client.create_collection(\n                collection_name=collection_name,\n                vectors_config=VectorParams(\n                    size=vector_size,\n                    distance=Distance.COSINE\n                )\n            )\n\n            return True\n\n        except Exception as e:\n            raise Exception(\n                f\"Failed to create collection {collection_name}: {str(e)}\")\n\n    # @check_cached_vector_store\n    def build_vector_store(self) -> Qdrant:\n        try:\n            collection_name = self.collection_name.get_text()\n            embedding: Embeddings = self.embedding\n\n            # Get host and port from inputs or environment variables\n            qdrant_host = self.qdrant_host.get_text() if hasattr(\n                self, 'qdrant_host') and self.qdrant_host else None\n            qdrant_port = self.qdrant_port.get_text() if hasattr(\n                self, 'qdrant_port') and self.qdrant_port else None\n\n            # If not provided in inputs, check environment variables\n            if not qdrant_host:\n                qdrant_host = os.getenv(\n                    'HOST_QDRANT_SERVICE', 'onlyoffice-qdrant')\n\n            if not qdrant_port:\n                qdrant_port = os.getenv('HOST_QDRANT_PORT', \"6333\")\n\n            # Create QdrantClient with HTTP and timeout\n            client = QdrantClient(\n                host=qdrant_host,\n                port=qdrant_port,  # HTTP/REST API port\n                prefer_grpc=False,  # Use HTTP\n                timeout=10.0  # Add timeout\n            )\n\n            if self.files:\n                if not self.check_collection_exists(client, collection_name):\n                    return None\n\n            if self.documents:\n                documents: List[str] = [\n                    i.data.get('text') for i in self.documents]\n\n                if not documents:\n                    raise ValueError(\"No documents provided\")\n\n            if not self.check_collection_exists(client, collection_name):\n                # Get vector size from first document\n                doc = Document(page_content='content for vectorize',\n                               metadata={**self.metadata.data})\n                vector = embedding.embed_query(doc.page_content)\n                vector_size = len(vector)\n                self.create_collection(\n                    client, collection_name, vector_size)\n\n            qdrant = Qdrant(client=client,\n                            embeddings=embedding,\n                            collection_name=collection_name)\n\n            return qdrant\n\n        except Exception as e:\n            raise Exception(f\"Error building vector store: {str(e)}\")\n\n    def check_document_exists(self, qdrant: Qdrant, document: Document) -> List[Document]:\n        # Only check if document has metadata with id and version\n        if not document.metadata or 'id' not in document.metadata or 'version' not in document.metadata:\n            return []\n\n        return qdrant.similarity_search(\n            query=document.page_content,\n            k=1,\n            filter=Filter(\n                must=[\n                    {\"key\": \"metadata.id\", \"match\": {\n                        \"value\": document.metadata['id']}},\n                    {\"key\": \"metadata.version\", \"match\": {\n                        \"value\": document.metadata['version']}},\n                ]\n            )\n        )\n\n    def check_document(self) -> Message:\n        qdrant = self.build_vector_store()\n\n        if not self.metadata:\n            return Message(text=\"No metadata provided\")\n\n        doc = Document(page_content=\"\", metadata={**self.metadata.data})\n\n        if self.check_document_exists(qdrant, doc):\n            return Message(text=\"exist\")\n\n        return Message(text=\"not_found\")\n\n    def vectorize_documents(self) -> Message:\n        try:\n            qdrant = self.build_vector_store()\n\n            if not self.documents:\n                return Message(text=\"No documents to process\")\n\n            metadata = self.metadata.data\n\n            docs: Dict[str, str] = [\n                Document(page_content=doc.data.get('text'), metadata={**metadata, \"page\": i}) for i, doc in enumerate(self.documents)]\n\n            if not docs:\n                return Message(text=\"No documents to process\")\n\n            if not metadata:\n                return Message(text=\"No metadata provided\")\n\n            if self.check_document_exists(qdrant, docs[0]):\n                return Message(text=\"exist\")\n\n            qdrant.add_documents(docs)\n\n            msg = Message(\n                text=f'added'\n            )\n\n            return msg\n\n        except Exception as e:\n            raise Exception(f\"Error vectorizing documents: {str(e)}\")\n\n    def search_documents(self) -> Message:\n        files: List[Dict[str, Any]] = self.files.data.get(\"files\", [])\n\n        if not files:\n            return Message(text=\"No files found in input\")\n\n        question: str = self.question.get_text()\n\n        if not question:\n            return Message(text=\"No question provided\")\n\n        qdrant = self.build_vector_store()\n\n        if not qdrant:\n            return Message(text=\", \".join([str(file.get('id', 'unknown')) for file in files]),\n                           data={\"docs\": []})\n\n        # Create a unique list of files based on id and version\n        unique_files = []\n        file_keys = set()\n\n        for file in files:\n            file_id = file.get('id', 'unknown')\n            file_version = file.get('version', 1)\n            file_key = f\"{file_id}_{file_version}\"\n\n            if file_key not in file_keys:\n                file_keys.add(file_key)\n                unique_files.append(file)\n\n        not_found_files = []\n\n        for file in unique_files:\n            if self.check_document_exists(qdrant, Document(\n                page_content=question,\n                metadata={\n                    \"id\": file.get('id', 'unknown'),\n                    \"version\": file.get('version', 1),\n                }\n            )):\n                continue\n\n            not_found_files.append(file)\n\n        if len(not_found_files):\n            return Message(text=\", \".join([str(file.get('id', 'unknown')) for file in files]),\n                           data={\"docs\": []})\n\n        # Create OR conditions for each file (file_id AND version must match)\n        file_conditions = [\n            {\n                \"must\": [\n                    {\"key\": \"metadata.id\", \"match\": {\n                        \"value\": file.get('id', 'unknown')}},\n                    {\"key\": \"metadata.version\", \"match\": {\n                        \"value\": file.get('version', 1)}}\n                ]\n            } for file in files\n        ]\n\n        filter: Filter = Filter(\n            should=file_conditions\n        )\n\n        docs = qdrant.similarity_search(\n            query=question,\n            k=5,\n            filter=filter\n        )\n\n        return Message(text=\", \".join([str(file.get('id', 'unknown')) for file in files]),\n                       data={\"docs\": docs})\n"
              },
              "collection_name": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "files"
              },
              "documents": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Documents",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "documents",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "files": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Files",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "metadata": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Metadata",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "qdrant_host": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Qdrant Host",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "qdrant_host",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "qdrant_port": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Qdrant Port",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "qdrant_port",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "question": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Question",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "restart_search": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Restart Search",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "restart_search",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DocSpaceQdrantVectorStoreComponent"
        },
        "dragging": false,
        "id": "DocSpaceQdrantVectorStoreComponent-XcFyR",
        "measured": {
          "height": 829,
          "width": 320
        },
        "position": {
          "x": 419.4798255872256,
          "y": 243.99807931582257
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIEmbeddings-TIJdh",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "name": "embeddings",
                "required_inputs": [
                  "openai_api_key"
                ],
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "client": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Client",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "client",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"
              },
              "default_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Headers",
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "default_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "default_query": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Query",
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "default_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "list_add_label": "Add More",
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "embedding_ctx_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Embedding Context Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding_ctx_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-large"
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "openai_api_base": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "openai_api_type": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Type",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_version": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Version",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_version",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_organization": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Organization",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_organization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_proxy": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Proxy",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_proxy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "show_progress_bar": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Show Progress Bar",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "show_progress_bar",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "skip_empty": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Skip Empty",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "skip_empty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tiktoken_enable": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "TikToken Enable",
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tiktoken_enable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tiktoken_model_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "TikToken Model Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tiktoken_model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIEmbeddings"
        },
        "dragging": false,
        "id": "OpenAIEmbeddings-TIJdh",
        "measured": {
          "height": 311,
          "width": 320
        },
        "position": {
          "x": -171.41394634212412,
          "y": 955.5694074266708
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-t2HjL",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-t2HjL",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 1383.6126265957037,
          "y": 1030.0457456563431
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -438.92297110386903,
      "y": -249.00193535322467,
      "zoom": 0.6446334428866788
    }
  },
  "description": "Get file content depend on user query.",
  "endpoint_name": null,
  "id": "4db3ea45-476c-4c40-8a15-cc5963aa4c89",
  "is_component": false,
  "last_tested_version": "1.2.0",
  "name": "get_context_from_files",
  "tags": []
}