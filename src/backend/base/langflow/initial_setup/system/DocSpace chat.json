{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseReferences",
            "id": "ParseReferences-PmPM8",
            "name": "parsed_references",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "TextInput-MXNgg",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParseReferences-PmPM8{œdataTypeœ:œParseReferencesœ,œidœ:œParseReferences-PmPM8œ,œnameœ:œparsed_referencesœ,œoutput_typesœ:[œDataœ]}-TextInput-MXNgg{œfieldNameœ:œdataœ,œidœ:œTextInput-MXNggœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "ParseReferences-PmPM8",
        "sourceHandle": "{œdataTypeœ:œParseReferencesœ,œidœ:œParseReferences-PmPM8œ,œnameœ:œparsed_referencesœ,œoutput_typesœ:[œDataœ]}",
        "target": "TextInput-MXNgg",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œTextInput-MXNggœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseReferences",
            "id": "ParseReferences-PmPM8",
            "name": "parsed_references",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "GetFilesFromFolders-cfjz8",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParseReferences-PmPM8{œdataTypeœ:œParseReferencesœ,œidœ:œParseReferences-PmPM8œ,œnameœ:œparsed_referencesœ,œoutput_typesœ:[œDataœ]}-GetFilesFromFolders-cfjz8{œfieldNameœ:œdataœ,œidœ:œGetFilesFromFolders-cfjz8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "ParseReferences-PmPM8",
        "sourceHandle": "{œdataTypeœ:œParseReferencesœ,œidœ:œParseReferences-PmPM8œ,œnameœ:œparsed_referencesœ,œoutput_typesœ:[œDataœ]}",
        "target": "GetFilesFromFolders-cfjz8",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œGetFilesFromFolders-cfjz8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GetFilesFromFolders",
            "id": "GetFilesFromFolders-cfjz8",
            "name": "files",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ConditionalRouter-ovaNy",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-GetFilesFromFolders-cfjz8{œdataTypeœ:œGetFilesFromFoldersœ,œidœ:œGetFilesFromFolders-cfjz8œ,œnameœ:œfilesœ,œoutput_typesœ:[œDataœ]}-ConditionalRouter-ovaNy{œfieldNameœ:œdataœ,œidœ:œConditionalRouter-ovaNyœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "GetFilesFromFolders-cfjz8",
        "sourceHandle": "{œdataTypeœ:œGetFilesFromFoldersœ,œidœ:œGetFilesFromFolders-cfjz8œ,œnameœ:œfilesœ,œoutput_typesœ:[œDataœ]}",
        "target": "ConditionalRouter-ovaNy",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œConditionalRouter-ovaNyœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RunFlow",
            "id": "RunFlow-2Uiy3",
            "name": "flow_outputs_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "document_context",
            "id": "RagPrompt-qmyvE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RunFlow-2Uiy3{œdataTypeœ:œRunFlowœ,œidœ:œRunFlow-2Uiy3œ,œnameœ:œflow_outputs_messageœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-qmyvE{œfieldNameœ:œdocument_contextœ,œidœ:œRagPrompt-qmyvEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RunFlow-2Uiy3",
        "sourceHandle": "{œdataTypeœ:œRunFlowœ,œidœ:œRunFlow-2Uiy3œ,œnameœ:œflow_outputs_messageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RagPrompt-qmyvE",
        "targetHandle": "{œfieldNameœ:œdocument_contextœ,œidœ:œRagPrompt-qmyvEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-aWQth",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "GetFoldersContent-BB14L",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TextInput-aWQth{œdataTypeœ:œTextInputœ,œidœ:œTextInput-aWQthœ,œnameœ:œtextœ,œoutput_typesœ:[œDataœ]}-GetFoldersContent-BB14L{œfieldNameœ:œdataœ,œidœ:œGetFoldersContent-BB14Lœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "TextInput-aWQth",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-aWQthœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GetFoldersContent-BB14L",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œGetFoldersContent-BB14Lœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "EnvExtractor",
            "id": "EnvExtractor-8LUE4",
            "name": "files_host",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "files_host",
            "id": "GetFoldersContent-BB14L",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-EnvExtractor-8LUE4{œdataTypeœ:œEnvExtractorœ,œidœ:œEnvExtractor-8LUE4œ,œnameœ:œfiles_hostœ,œoutput_typesœ:[œMessageœ]}-GetFoldersContent-BB14L{œfieldNameœ:œfiles_hostœ,œidœ:œGetFoldersContent-BB14Lœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "EnvExtractor-8LUE4",
        "sourceHandle": "{œdataTypeœ:œEnvExtractorœ,œidœ:œEnvExtractor-8LUE4œ,œnameœ:œfiles_hostœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GetFoldersContent-BB14L",
        "targetHandle": "{œfieldNameœ:œfiles_hostœ,œidœ:œGetFoldersContent-BB14Lœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-SWisu",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "memory",
            "id": "SystemPrompt-jJI3d",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Memory-SWisu{œdataTypeœ:œMemoryœ,œidœ:œMemory-SWisuœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-SystemPrompt-jJI3d{œfieldNameœ:œmemoryœ,œidœ:œSystemPrompt-jJI3dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Memory-SWisu",
        "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-SWisuœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SystemPrompt-jJI3d",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œSystemPrompt-jJI3dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-SWisu",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "memory",
            "id": "RagPrompt-qmyvE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Memory-SWisu{œdataTypeœ:œMemoryœ,œidœ:œMemory-SWisuœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-qmyvE{œfieldNameœ:œmemoryœ,œidœ:œRagPrompt-qmyvEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Memory-SWisu",
        "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-SWisuœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RagPrompt-qmyvE",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œRagPrompt-qmyvEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RunFlow",
            "id": "RunFlow-OqJHt",
            "name": "flow_outputs_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "document_context",
            "id": "RagPrompt-SR3ZC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RunFlow-OqJHt{œdataTypeœ:œRunFlowœ,œidœ:œRunFlow-OqJHtœ,œnameœ:œflow_outputs_messageœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-SR3ZC{œfieldNameœ:œdocument_contextœ,œidœ:œRagPrompt-SR3ZCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RunFlow-OqJHt",
        "sourceHandle": "{œdataTypeœ:œRunFlowœ,œidœ:œRunFlow-OqJHtœ,œnameœ:œflow_outputs_messageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RagPrompt-SR3ZC",
        "targetHandle": "{œfieldNameœ:œdocument_contextœ,œidœ:œRagPrompt-SR3ZCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-SWisu",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "memory",
            "id": "RagPrompt-SR3ZC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Memory-SWisu{œdataTypeœ:œMemoryœ,œidœ:œMemory-SWisuœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-SR3ZC{œfieldNameœ:œmemoryœ,œidœ:œRagPrompt-SR3ZCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Memory-SWisu",
        "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-SWisuœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RagPrompt-SR3ZC",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œRagPrompt-SR3ZCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-78qPN",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "InputParser-lGm6i",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-78qPN{œdataTypeœ:œChatInputœ,œidœ:œChatInput-78qPNœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-InputParser-lGm6i{œfieldNameœ:œinputœ,œidœ:œInputParser-lGm6iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-78qPN",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-78qPNœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "InputParser-lGm6i",
        "targetHandle": "{œfieldNameœ:œinputœ,œidœ:œInputParser-lGm6iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "InputParser",
            "id": "InputParser-lGm6i",
            "name": "parsed_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ConditionalRouter-BiG8Y",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-InputParser-lGm6i{œdataTypeœ:œInputParserœ,œidœ:œInputParser-lGm6iœ,œnameœ:œparsed_dataœ,œoutput_typesœ:[œDataœ]}-ConditionalRouter-BiG8Y{œfieldNameœ:œdataœ,œidœ:œConditionalRouter-BiG8Yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "InputParser-lGm6i",
        "sourceHandle": "{œdataTypeœ:œInputParserœ,œidœ:œInputParser-lGm6iœ,œnameœ:œparsed_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ConditionalRouter-BiG8Y",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œConditionalRouter-BiG8Yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-78qPN",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-Ral8S",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-78qPN{œdataTypeœ:œChatInputœ,œidœ:œChatInput-78qPNœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-Ral8S{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-Ral8Sœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-78qPN",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-78qPNœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-Ral8S",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-Ral8Sœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RagPrompt",
            "id": "RagPrompt-SR3ZC",
            "name": "rag_prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-Ral8S",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RagPrompt-SR3ZC{œdataTypeœ:œRagPromptœ,œidœ:œRagPrompt-SR3ZCœ,œnameœ:œrag_promptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-Ral8S{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-Ral8Sœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RagPrompt-SR3ZC",
        "sourceHandle": "{œdataTypeœ:œRagPromptœ,œidœ:œRagPrompt-SR3ZCœ,œnameœ:œrag_promptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-Ral8S",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-Ral8Sœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-Ral8S",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-MwOz3",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-Ral8S{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ral8Sœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-MwOz3{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-MwOz3œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "source": "OpenAIModel-Ral8S",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ral8Sœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-MwOz3",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-MwOz3œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RagPrompt",
            "id": "RagPrompt-qmyvE",
            "name": "rag_prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-cNRSz",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RagPrompt-qmyvE{œdataTypeœ:œRagPromptœ,œidœ:œRagPrompt-qmyvEœ,œnameœ:œrag_promptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-cNRSz{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-cNRSzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RagPrompt-qmyvE",
        "sourceHandle": "{œdataTypeœ:œRagPromptœ,œidœ:œRagPrompt-qmyvEœ,œnameœ:œrag_promptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-cNRSz",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-cNRSzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-MXNgg",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-cNRSz",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-MXNgg{œdataTypeœ:œTextInputœ,œidœ:œTextInput-MXNggœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-cNRSz{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-cNRSzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "TextInput-MXNgg",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-MXNggœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-cNRSz",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-cNRSzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-cNRSz",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-xiNof",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-cNRSz{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cNRSzœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-xiNof{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-xiNofœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "source": "OpenAIModel-cNRSz",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cNRSzœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-xiNof",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-xiNofœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-nFwIp",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-b69hZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-nFwIp{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nFwIpœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-b69hZ{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-b69hZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "OpenAIModel-nFwIp",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nFwIpœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-b69hZ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-b69hZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-b69hZ",
            "name": "output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-ywIxf~input_value",
            "id": "RunFlow-OqJHt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CustomComponent-b69hZ{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b69hZœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-RunFlow-OqJHt{œfieldNameœ:œTextInput-ywIxf~input_valueœ,œidœ:œRunFlow-OqJHtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "CustomComponent-b69hZ",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b69hZœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "RunFlow-OqJHt",
        "targetHandle": "{œfieldNameœ:œTextInput-ywIxf~input_valueœ,œidœ:œRunFlow-OqJHtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-78qPN",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-9IOWc~input_value",
            "id": "RunFlow-OqJHt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-78qPN{œdataTypeœ:œChatInputœ,œidœ:œChatInput-78qPNœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-RunFlow-OqJHt{œfieldNameœ:œTextInput-9IOWc~input_valueœ,œidœ:œRunFlow-OqJHtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-78qPN",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-78qPNœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RunFlow-OqJHt",
        "targetHandle": "{œfieldNameœ:œTextInput-9IOWc~input_valueœ,œidœ:œRunFlow-OqJHtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-MXNgg",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-9IOWc~input_value",
            "id": "RunFlow-2Uiy3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-MXNgg{œdataTypeœ:œTextInputœ,œidœ:œTextInput-MXNggœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-RunFlow-2Uiy3{œfieldNameœ:œTextInput-9IOWc~input_valueœ,œidœ:œRunFlow-2Uiy3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "TextInput-MXNgg",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-MXNggœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RunFlow-2Uiy3",
        "targetHandle": "{œfieldNameœ:œTextInput-9IOWc~input_valueœ,œidœ:œRunFlow-2Uiy3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SystemPrompt",
            "id": "SystemPrompt-jJI3d",
            "name": "system_prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-nFwIp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-SystemPrompt-jJI3d{œdataTypeœ:œSystemPromptœ,œidœ:œSystemPrompt-jJI3dœ,œnameœ:œsystem_promptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-nFwIp{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-nFwIpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "SystemPrompt-jJI3d",
        "sourceHandle": "{œdataTypeœ:œSystemPromptœ,œidœ:œSystemPrompt-jJI3dœ,œnameœ:œsystem_promptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-nFwIp",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-nFwIpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GetFoldersContent",
            "id": "GetFoldersContent-BB14L",
            "name": "folder_content",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "document_context",
            "id": "SystemPrompt-jJI3d",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-GetFoldersContent-BB14L{œdataTypeœ:œGetFoldersContentœ,œidœ:œGetFoldersContent-BB14Lœ,œnameœ:œfolder_contentœ,œoutput_typesœ:[œDataœ]}-SystemPrompt-jJI3d{œfieldNameœ:œdocument_contextœ,œidœ:œSystemPrompt-jJI3dœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "GetFoldersContent-BB14L",
        "sourceHandle": "{œdataTypeœ:œGetFoldersContentœ,œidœ:œGetFoldersContent-BB14Lœ,œnameœ:œfolder_contentœ,œoutput_typesœ:[œDataœ]}",
        "target": "SystemPrompt-jJI3d",
        "targetHandle": "{œfieldNameœ:œdocument_contextœ,œidœ:œSystemPrompt-jJI3dœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouterList",
            "id": "ConditionalRouter-BiG8Y",
            "name": "true_result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "ParseReferences-PmPM8",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ConditionalRouter-BiG8Y{œdataTypeœ:œConditionalRouterListœ,œidœ:œConditionalRouter-BiG8Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseReferences-PmPM8{œfieldNameœ:œinputœ,œidœ:œParseReferences-PmPM8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "ConditionalRouter-BiG8Y",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterListœ,œidœ:œConditionalRouter-BiG8Yœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseReferences-PmPM8",
        "targetHandle": "{œfieldNameœ:œinputœ,œidœ:œParseReferences-PmPM8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouterList",
            "id": "ConditionalRouter-ovaNy",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-ywIxf~input_value",
            "id": "RunFlow-2Uiy3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-ovaNy{œdataTypeœ:œConditionalRouterListœ,œidœ:œConditionalRouter-ovaNyœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-RunFlow-2Uiy3{œfieldNameœ:œTextInput-ywIxf~input_valueœ,œidœ:œRunFlow-2Uiy3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ConditionalRouter-ovaNy",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterListœ,œidœ:œConditionalRouter-ovaNyœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "RunFlow-2Uiy3",
        "targetHandle": "{œfieldNameœ:œTextInput-ywIxf~input_valueœ,œidœ:œRunFlow-2Uiy3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouterList",
            "id": "ConditionalRouter-BiG8Y",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-nFwIp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-BiG8Y{œdataTypeœ:œConditionalRouterListœ,œidœ:œConditionalRouter-BiG8Yœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-nFwIp{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-nFwIpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ConditionalRouter-BiG8Y",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterListœ,œidœ:œConditionalRouter-BiG8Yœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-nFwIp",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-nFwIpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ChatInput-78qPN",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-78qPN",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": -575.6915469030305,
          "y": 923.6702876399132
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-BiG8Y",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": null,
                "method": "true_response",
                "name": "true_result",
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import DataInput\nfrom langflow.schema import Message, Data\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouterList\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Parsed data\",\n            info=\"Parsed data\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self) -> bool:\n        data: Data = self.data\n        \n        if not data.data:\n            return False\n        \n        references = data.data.get('references', [])\n        \n        return len(references)\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Data:\n        result = self.evaluate_condition()\n        \n        if result:\n            self.iterate_and_stop_once(\"false_result\")\n            return self.data\n       \n      \n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition()\n        \n        if not result:\n            self.iterate_and_stop_once(\"true_result\")\n            return self.data.data.get('question', '')\n        \n     \n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Parsed data",
                "dynamic": false,
                "info": "Parsed data",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouterList"
        },
        "dragging": false,
        "id": "ConditionalRouter-BiG8Y",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 222.71115461619974,
          "y": 1096.0079008216633
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RunFlow-2Uiy3",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a tool component from a Flow that takes all its inputs and runs it.  \n **Select a Flow to use the tool mode**",
            "display_name": "Run Flow",
            "documentation": "",
            "edited": false,
            "field_order": [
              "flow_name_selected",
              "session_id"
            ],
            "frozen": false,
            "icon": "Workflow",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Data Output",
                "hidden": true,
                "method": "data_output",
                "name": "flow_outputs_data",
                "required_inputs": [],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Dataframe Output",
                "hidden": true,
                "method": "dataframe_output",
                "name": "flow_outputs_dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Message Output",
                "method": "message_output",
                "name": "flow_outputs_message",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom loguru import logger\n\nfrom langflow.base.tools.run_flow import RunFlowBaseComponent\nfrom langflow.helpers.flow import run_flow\nfrom langflow.schema import dotdict\n\n\nclass RunFlowComponent(RunFlowBaseComponent):\n    display_name = \"Run Flow\"\n    description = (\n        \"Creates a tool component from a Flow that takes all its inputs and runs it. \"\n        \" \\n **Select a Flow to use the tool mode**\"\n    )\n    beta = True\n    name = \"RunFlow\"\n    icon = \"Workflow\"\n\n    inputs = RunFlowBaseComponent._base_inputs\n    outputs = RunFlowBaseComponent._base_outputs\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name_selected\":\n            build_config[\"flow_name_selected\"][\"options\"] = await self.get_flow_names()\n            missing_keys = [key for key in self.default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n            if field_value is not None:\n                try:\n                    graph = await self.get_graph(field_value)\n                    build_config = self.update_build_config_from_graph(build_config, graph)\n                except Exception as e:\n                    msg = f\"Error building graph for flow {field_value}\"\n                    logger.exception(msg)\n                    raise RuntimeError(msg) from e\n        return build_config\n\n    async def run_flow_with_tweaks(self):\n        tweaks: dict = {}\n\n        flow_name_selected = self._attributes.get(\"flow_name_selected\")\n        parsed_flow_tweak_data = self._attributes.get(\"flow_tweak_data\", {})\n        if not isinstance(parsed_flow_tweak_data, dict):\n            parsed_flow_tweak_data = parsed_flow_tweak_data.dict()\n\n        if parsed_flow_tweak_data != {}:\n            for field in parsed_flow_tweak_data:\n                if \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = parsed_flow_tweak_data[field]\n        else:\n            for field in self._attributes:\n                if field not in self.default_keys and \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = self._attributes[field]\n\n        return await run_flow(\n            inputs=None,\n            output_type=\"all\",\n            flow_id=None,\n            flow_name=flow_name_selected,\n            tweaks=tweaks,\n            user_id=str(self.user_id),\n            session_id=self.graph.session_id or self.session_id,\n        )\n"
              },
              "flow_name_selected": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Flow Name",
                "dynamic": false,
                "info": "The name of the flow to run.",
                "name": "flow_name_selected",
                "options": [],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Get context from files"
              },
              "session_id": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID to run the flow in.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": {
                  "data": {
                    "files": [],
                    "text": "",
                    "timestamp": "2025-03-04 09:26:02 UTC"
                  },
                  "default_value": "",
                  "text_key": "text"
                }
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RunFlow"
        },
        "dragging": false,
        "id": "RunFlow-2Uiy3",
        "measured": {
          "height": 435,
          "width": 320
        },
        "position": {
          "x": 1874.0153737048265,
          "y": 896.2158054420645
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseReferences-PmPM8",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Parse references from input data to extract files, folders, and flags.",
            "display_name": "Parse References",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed references",
                "method": "parse_references",
                "name": "parsed_references",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List, Dict, Any, Union\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DataInput\nfrom langflow.io import Output\nfrom langflow.schema import Data, Message\n\n\nclass ReferencesParserComponent(Component):\n    display_name: str = \"Parse References\"\n    description: str = \"Parse references from input data to extract files, folders, and flags.\"\n    name: str = \"ParseReferences\"\n    icon = \"braces\"\n\n    inputs = [\n        DataInput(\n            name=\"input\",\n            display_name=\"Data\",\n            info=\"Input data containing references\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Parsed references\",\n               name=\"parsed_references\", method=\"parse_references\"),\n    ]\n\n    def parse_references(self) -> Data:\n        \"\"\"Parse input data to extract and categorize references.\n\n        Sorts input array into:\n        - files: numeric IDs as integers\n        - folders: folder numbers extracted from 'folder-X' format\n        - docspace_api: True if 'docspace-api' is in the input\n        - docspace_sdk: True if 'docspace-sdk' is in the input\n\n        Returns:\n            Data: Parsed references with files, folders, and flags\n        \"\"\"\n        input_data = self.input.data\n\n        if not input_data:\n            return Data(data={\n                \"files\": [],\n                \"folders\": [],\n                \"docspace_api\": False,\n                \"docspace_sdk\": False\n            })\n\n        # Extract references from input\n        references = input_data.get(\"references\", [])\n\n        # Initialize result containers\n        files = []\n        folders = []\n        docspace_api = False\n        docspace_sdk = False\n\n        # Process each reference\n        for ref in references:\n            # Convert to string to handle different types\n            ref_str = str(ref).strip()\n\n            # Check if it's a file ID (numeric)\n            if ref_str.isdigit():\n                files.append(int(ref_str))\n            # Check if it's a folder reference\n            elif ref_str.startswith(\"folder-\"):\n                try:\n                    folder_id = int(ref_str.replace(\"folder-\", \"\"))\n                    folders.append(folder_id)\n                except ValueError:\n                    # Skip invalid folder format\n                    pass\n            # Check for docspace API/SDK flags\n            elif ref_str == \"docspace-api\":\n                docspace_api = True\n            elif ref_str == \"docspace-sdk\":\n                docspace_sdk = True\n\n        # Return structured data\n        return Data(data={\n            \"files\": files,\n            \"folders\": folders,\n            \"docspace_api\": docspace_api,\n            \"docspace_sdk\": docspace_sdk\n        })\n"
              },
              "input": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Input data containing references",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseReferences"
        },
        "dragging": false,
        "id": "ParseReferences-PmPM8",
        "measured": {
          "height": 212,
          "width": 320
        },
        "position": {
          "x": 678.6053305529712,
          "y": 934.6952536665756
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-ovaNy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else Files",
            "documentation": "",
            "edited": true,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": null,
                "method": "true_response",
                "name": "true_result",
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List\nfrom langflow.custom import Component\nfrom langflow.io import DataInput\nfrom langflow.schema.message import Message, Data\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else Files\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouterList\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Parsed data\",\n            info=\"Parsed data\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self) -> bool:\n        data: Data = self.data\n        \n        if not data.data:\n            return False\n        \n        files = data.data.get('files', [])\n        \n        return len(files)\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition()\n        \n        if result:\n            self.iterate_and_stop_once(\"false_result\")\n            return \",\".join(str(file) for file in self.data.data.get(\"files\"))\n       \n      \n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition()\n        \n        if not result:\n            self.iterate_and_stop_once(\"true_result\")\n            return \"\"\n        \n     \n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Parsed data",
                "dynamic": false,
                "info": "Parsed data",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouterList"
        },
        "dragging": false,
        "id": "ConditionalRouter-ovaNy",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 1475.9805948811124,
          "y": 946.8405851261984
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-MXNgg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get question from data.",
            "display_name": "Question",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-MXNgg",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": 1116.2054750408136,
          "y": 1296.6842518544854
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GetFilesFromFolders-cfjz8",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts files from DocSpace folders and returns their metadata including IDs, names, and content types",
            "display_name": "Get Files From Folders",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "asc_auth_key"
            ],
            "frozen": false,
            "icon": "file-search",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Files",
                "method": "get_files_from_folders",
                "name": "files",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asc_auth_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Auth key",
                "dynamic": false,
                "info": "Auth key to use",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "asc_auth_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "asc_auth_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import MessageInput, DataInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\n\n\nclass GetFilesFromFoldersComponent(Component):\n    \"\"\"Component for extracting files from DocSpace folders via API.\"\"\"\n\n    display_name: str = \"Get Files From Folders\"\n    description: str = \"Extracts files from DocSpace folders and returns their metadata including IDs, names, and content types\"\n    name: str = \"GetFilesFromFolders\"\n    icon = \"file-search\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Folders and Files IDs\",\n            info=\"IDs of the folders and files to get\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"asc_auth_key\",\n            display_name=\"Auth key\",\n            info=\"Auth key to use\",\n            required=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            name=\"files\",\n            display_name=\"Files\",\n            method=\"get_files_from_folders\",\n        ),\n    ]\n\n    async def get_folder(self, session: aiohttp.ClientSession, folder_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Make an async API request to get folder information from DocSpace.\n\n        Args:\n            session: aiohttp client session\n            folder_id: ID of the folder to retrieve\n\n        Returns:\n            Dict containing the folder information including metadata and contents\n        \"\"\"\n        try:\n            headers = {\n                'Authorization': self.asc_auth_key,\n            }\n\n            files_host = os.environ.get('HOST_FILES_SERVICE', 'http://onlyoffice-files:5050')\n            url = f'{files_host}/api/2.0/files/{folder_id}'\n\n            async with session.get(url, headers=headers, timeout=30) as response:\n                response.raise_for_status()\n                data = await response.json()\n                return data[\"response\"]\n\n        except Exception as e:\n            print(f\"Error getting folder {folder_id}: {str(e)}\")\n            return None\n\n    async def fetch_all_folders(self, folder_ids: List[str]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Fetch all folders concurrently using aiohttp for efficient retrieval.\n\n        Args:\n            folder_ids: List of folder IDs to fetch from DocSpace\n\n        Returns:\n            List of folder information dictionaries with complete metadata\n        \"\"\"\n        async with aiohttp.ClientSession() as session:\n            # Create tasks for all file fetches\n            tasks = [self.get_folder(session, folder_id)\n                     for folder_id in folder_ids]\n            # Wait for all tasks to complete (like Promise.all)\n            results = await asyncio.gather(*tasks)\n            # Filter out None results (failed requests)\n            return [r for r in results if r is not None]\n\n    async def get_files_from_folders(self) -> Data:\n        \"\"\"\n        Make concurrent API requests to retrieve folders from DocSpace and extract their files.\n        Processes the input folder IDs, fetches folder information, and extracts file metadata.\n\n        Returns:\n            Data object containing a list of file information dictionaries extracted from the folders\n        \"\"\"\n        try:\n            # Get folder IDs from input data\n            folders_data: List[str] = self.data.data.get(\n                \"folders\", [])\n            files_data: List[str] = self.data.data.get(\n                \"files\", [])\n\n            if not folders_data and not files_data:\n                return Data(data={\"files\": []})\n\n            if not folders_data:\n                return Data(data={\"files\": files_data})\n\n            # Fetch all folders concurrently\n            folders_info = await self.fetch_all_folders(folders_data)\n\n            # Extract files from all folders\n            files_info = []\n            for folder in folders_info:\n                if \"files\" in folder and isinstance(folder[\"files\"], list):\n                    files_info.extend(folder[\"files\"])\n\n            # Extract file IDs from folder files\n            folder_file_ids = [file.get('id', '')\n                               for file in files_info if file.get('id')]\n\n            # Merge with files_data and remove duplicates using a set\n            all_file_ids = set(folder_file_ids)\n            all_file_ids.update([file_id for file_id in files_data if file_id])\n\n            # Convert back to list\n            unique_files = list(all_file_ids)\n\n            return Data(data={\"files\": unique_files})\n\n        except Exception as e:\n            return Data(data={\"files\": []})\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Folders and Files IDs",
                "dynamic": false,
                "info": "IDs of the folders and files to get",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GetFilesFromFolders"
        },
        "dragging": false,
        "id": "GetFilesFromFolders-cfjz8",
        "measured": {
          "height": 314,
          "width": 320
        },
        "position": {
          "x": 1101.3936852683325,
          "y": 881.7143561599348
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-aWQth",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Current folder to start flow",
            "display_name": "Current folder",
            "documentation": "",
            "edited": false,
            "field_order": [
              "current_folder"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-aWQth",
        "measured": {
          "height": 230,
          "width": 320
        },
        "position": {
          "x": -809.1044146512302,
          "y": 1878.0130236846019
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RagPrompt-qmyvE",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a structured RAG prompt with document context for retrieval-augmented generation.",
            "display_name": "RAG Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "document_context",
              "memory"
            ],
            "frozen": false,
            "icon": "file-text",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "RAG Prompt",
                "method": "format_rag_prompt",
                "name": "rag_prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema.message import Message\n\nRAG_PROMPT = \"\"\" \nDOCUMENTS:\n{document}\n\nHISTORY:\n{memory}\n\nINSTRUCTIONS:\nAnswer the users QUESTION using the DOCUMENTS text above.\nKeep your answer ground in the facts of the DOCUMENTS.\nIf the DOCUMENTS doesn't contain the facts to answer the QUESTION return 'Not known'\nPrefer use DOCUMENTS. If DOCUMENTS are empty or not contain answer - use HISTORY.\n\"\"\"\n\n\nclass RagPromptComponent(Component):\n    \"\"\"\n    Component that formats a RAG prompt with document context.\n    Creates a structured prompt for retrieval-augmented generation.\n    \"\"\"\n\n    display_name = \"RAG Prompt\"\n    description = \"Creates a structured RAG prompt with document context for retrieval-augmented generation.\"\n    icon = \"file-text\"\n    name = \"RagPrompt\"\n\n    inputs = [\n        MessageInput(\n            name=\"document_context\",\n            display_name=\"Document context\",\n            info=\"The context of the document to combine with others\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"memory\",\n            display_name=\"Chat memory\",\n            info=\"Chat memory\"\n        )\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"RAG Prompt\",\n            name=\"rag_prompt\",\n            method=\"format_rag_prompt\",\n        ),\n    ]\n\n    def format_rag_prompt(self) -> Message:\n        \"\"\"\n        Formats a RAG prompt with the provided document context.\n\n        Returns:\n            Message: A message containing the formatted RAG prompt\n        \"\"\"\n        # Get the document context\n        doc_msg = self.document_context\n        document_content = doc_msg.get_text() if doc_msg else \"\"\n\n        # Format the RAG prompt template with the document context\n        formatted_prompt = RAG_PROMPT.format(\n            document=document_content, memory=self.memory.get_text())\n\n        # Create a new message with the formatted prompt\n        # Preserve metadata from the document context message\n        rag_prompt_msg = Message(\n            text=formatted_prompt,\n            sender=doc_msg.sender if doc_msg else None,\n            sender_name=doc_msg.sender_name if doc_msg else None,\n            session_id=doc_msg.session_id if doc_msg else None,\n            flow_id=doc_msg.flow_id if doc_msg else None,\n        )\n\n        return rag_prompt_msg\n"
              },
              "document_context": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Document context",
                "dynamic": false,
                "info": "The context of the document to combine with others",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "document_context",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "memory": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Chat memory",
                "dynamic": false,
                "info": "Chat memory",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RagPrompt"
        },
        "dragging": false,
        "id": "RagPrompt-qmyvE",
        "measured": {
          "height": 352,
          "width": 320
        },
        "position": {
          "x": 2263.7286498175868,
          "y": 1068.8140505472413
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SystemPrompt-jJI3d",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a system prompt that informs the AI assistant about available folders and documents.",
            "display_name": "System Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "document_context",
              "memory"
            ],
            "frozen": false,
            "icon": "terminal",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "System Prompt",
                "method": "format_system_prompt",
                "name": "system_prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import DataInput, Output, MessageInput\nfrom langflow.schema.message import Message\n\nSYSTEM_PROMPT = \"\"\" \nYou are a helpful assistant that can use tools to answer questions and perform tasks.\nInside input found title of documents or folders. Later your need use tools with this ids.\nIf name of folders or documents not available - do not use tools.\nIf you dont see file or folder from user question - just return user question.\nIf extensions is empty - it is folder. This folder can has subfolders or files \nfrom user query. Your asnwer ONLY id for file or files that ACCEPT USER.\nFile or folder ID or title MAY BE inside HISTORY with @ID.\n@1 - is it file with id 1.\n@folder-1 - is it folder with id 1.\nExample: 1,2,3,4 \nWithout spaces. No need to use @.\n\nList of available folders and documents:\n{folders_and_documents}\n\nHISTORY:\n{memory}\n\"\"\"\n\n\nclass SystemPromptComponent(Component):\n    \"\"\"\n    Component that formats a system prompt with available folders and documents.\n    Creates a structured prompt that instructs an AI assistant about available documents and folders.\n    \"\"\"\n\n    display_name = \"System Prompt\"\n    description = \"Creates a system prompt that informs the AI assistant about available folders and documents.\"\n    icon = \"terminal\"\n    name = \"SystemPrompt\"\n\n    inputs = [\n        DataInput(\n            name=\"document_context\",\n            display_name=\"Folders and Documents\",\n            info=\"List of available folders and documents to include in the system prompt\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"memory\",\n            display_name=\"Chat memory\",\n            info=\"Chat memory\"\n        )\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"System Prompt\",\n            name=\"system_prompt\",\n            method=\"format_system_prompt\",\n        ),\n    ]\n\n    def format_system_prompt(self) -> Message:\n        \"\"\"\n        Formats a system prompt with the provided folders and documents information.\n\n        Returns:\n            Message: A message containing the formatted system prompt\n        \"\"\"\n        # Get the document context\n        folders_and_documents = self.document_context.data.get(\"content\", [])\n\n        formated_content = \"\\n\".join(\n            f'Title: {str(item.get('title'))} id: {str(item.get('id'))} extension: {str(item.get('fileExst', ''))}' for item in folders_and_documents)\n\n        # Format the system prompt template with the document context\n        formatted_prompt = SYSTEM_PROMPT.format(\n            folders_and_documents=formated_content,\n            memory=self.memory.get_text()\n        )\n\n        # Create a new message with the formatted prompt\n        # Preserve metadata from the document context message\n        system_prompt_msg = Message(\n            text=formatted_prompt,\n        )\n\n        return system_prompt_msg\n"
              },
              "document_context": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Folders and Documents",
                "dynamic": false,
                "info": "List of available folders and documents to include in the system prompt",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "document_context",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Chat memory",
                "dynamic": false,
                "info": "Chat memory",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SystemPrompt"
        },
        "dragging": false,
        "id": "SystemPrompt-jJI3d",
        "measured": {
          "height": 314,
          "width": 320
        },
        "position": {
          "x": 439.79724845938375,
          "y": 2392.669228247825
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GetFoldersContent-BB14L",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves folder content including files, subfolders, and metadata from DocSpace",
            "display_name": "Get Folder Content",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "asc_auth_key",
              "files_host"
            ],
            "frozen": false,
            "icon": "folder-open",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Folder Content",
                "method": "get_files_from_folders",
                "name": "folder_content",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asc_auth_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Auth key",
                "dynamic": false,
                "info": "Auth key to use",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "asc_auth_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "asc_auth_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import MessageInput, DataInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\n\n\nclass GetFoldersContentComponent(Component):\n    \"\"\"Component for retrieving complete folder content from DocSpace via API.\"\"\"\n\n    display_name: str = \"Get Folder Content\"\n    description: str = \"Retrieves folder content including files, subfolders, and metadata from DocSpace\"\n    name: str = \"GetFoldersContent\"\n    icon = \"folder-open\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Folders and Files IDs\",\n            info=\"IDs of the folders and files to get\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"asc_auth_key\",\n            display_name=\"Auth key\",\n            info=\"Auth key to use\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"files_host\",\n            display_name=\"Files Service Host\",\n            info=\"Host URL for the files service\",\n            required=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            name=\"folder_content\",\n            display_name=\"Folder Content\",\n            method=\"get_files_from_folders\",\n        ),\n    ]\n\n    async def get_folder(self, session: aiohttp.ClientSession, folder_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Make an async API request to get folder information from DocSpace.\n\n        Args:\n            session: aiohttp client session\n            folder_id: ID of the folder to retrieve\n\n        Returns:\n            Dict containing the folder information including metadata and contents\n        \"\"\"\n        try:\n            headers = {\n                'Authorization': self.asc_auth_key,\n            }\n\n            files_host = self.files_host.get_text()\n            url = f'{files_host}/api/2.0/files/{folder_id}'\n\n            async with session.get(url, headers=headers, timeout=30) as response:\n                response.raise_for_status()\n                data = await response.json()\n                return data[\"response\"]\n\n        except Exception as e:\n            print(f\"Error getting folder {folder_id}: {str(e)}\")\n            return None\n\n    async def fetch_all_folders(self, folder_ids: List[str]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Fetch all folders concurrently using aiohttp for efficient retrieval.\n\n        Args:\n            folder_ids: List of folder IDs to fetch from DocSpace\n\n        Returns:\n            List of folder information dictionaries with complete metadata\n        \"\"\"\n        async with aiohttp.ClientSession() as session:\n            # Create tasks for all file fetches\n            tasks = [self.get_folder(session, folder_id)\n                     for folder_id in folder_ids]\n            # Wait for all tasks to complete (like Promise.all)\n            results = await asyncio.gather(*tasks)\n            # Filter out None results (failed requests)\n            return [r for r in results if r is not None]\n\n    async def get_files_from_folders(self) -> Data:\n        \"\"\"\n        Make concurrent API requests to retrieve folders from DocSpace and extract their files.\n        Processes the input folder IDs, fetches folder information, and extracts file metadata.\n\n        Returns:\n            Data object containing a list of file information dictionaries extracted from the folders\n        \"\"\"\n        try:\n            # Get folder IDs from input data\n            folders_data: List[str] = self.data.data.get(\n                \"folders\", [])\n\n            if not folders_data:\n                return Data(data={\"content\": []})\n\n            # Fetch all folders concurrently\n            folders_info = await self.fetch_all_folders(folders_data)\n\n            content = []\n\n            content.extend(folders_info[0].get('folders', []))\n            content.extend(folders_info[0].get('files', []))\n\n            return Data(data={\"content\": content})\n\n        except Exception as e:\n            return Data(data={\"content\": []})\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Folders and Files IDs",
                "dynamic": false,
                "info": "IDs of the folders and files to get",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "files_host": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Files Service Host",
                "dynamic": false,
                "info": "Host URL for the files service",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "files_host",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GetFoldersContent"
        },
        "dragging": false,
        "id": "GetFoldersContent-BB14L",
        "measured": {
          "height": 377,
          "width": 320
        },
        "position": {
          "x": -315.040000863248,
          "y": 1889.2604876364394
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RunFlow-OqJHt",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a tool component from a Flow that takes all its inputs and runs it.  \n **Select a Flow to use the tool mode**",
            "display_name": "Run Flow",
            "documentation": "",
            "edited": false,
            "field_order": [
              "flow_name_selected",
              "session_id"
            ],
            "frozen": false,
            "icon": "Workflow",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Data Output",
                "hidden": true,
                "method": "data_output",
                "name": "flow_outputs_data",
                "required_inputs": [],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Dataframe Output",
                "hidden": true,
                "method": "dataframe_output",
                "name": "flow_outputs_dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Message Output",
                "method": "message_output",
                "name": "flow_outputs_message",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom loguru import logger\n\nfrom langflow.base.tools.run_flow import RunFlowBaseComponent\nfrom langflow.helpers.flow import run_flow\nfrom langflow.schema import dotdict\n\n\nclass RunFlowComponent(RunFlowBaseComponent):\n    display_name = \"Run Flow\"\n    description = (\n        \"Creates a tool component from a Flow that takes all its inputs and runs it. \"\n        \" \\n **Select a Flow to use the tool mode**\"\n    )\n    beta = True\n    name = \"RunFlow\"\n    icon = \"Workflow\"\n\n    inputs = RunFlowBaseComponent._base_inputs\n    outputs = RunFlowBaseComponent._base_outputs\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name_selected\":\n            build_config[\"flow_name_selected\"][\"options\"] = await self.get_flow_names()\n            missing_keys = [key for key in self.default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n            if field_value is not None:\n                try:\n                    graph = await self.get_graph(field_value)\n                    build_config = self.update_build_config_from_graph(build_config, graph)\n                except Exception as e:\n                    msg = f\"Error building graph for flow {field_value}\"\n                    logger.exception(msg)\n                    raise RuntimeError(msg) from e\n        return build_config\n\n    async def run_flow_with_tweaks(self):\n        tweaks: dict = {}\n\n        flow_name_selected = self._attributes.get(\"flow_name_selected\")\n        parsed_flow_tweak_data = self._attributes.get(\"flow_tweak_data\", {})\n        if not isinstance(parsed_flow_tweak_data, dict):\n            parsed_flow_tweak_data = parsed_flow_tweak_data.dict()\n\n        if parsed_flow_tweak_data != {}:\n            for field in parsed_flow_tweak_data:\n                if \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = parsed_flow_tweak_data[field]\n        else:\n            for field in self._attributes:\n                if field not in self.default_keys and \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = self._attributes[field]\n\n        return await run_flow(\n            inputs=None,\n            output_type=\"all\",\n            flow_id=None,\n            flow_name=flow_name_selected,\n            tweaks=tweaks,\n            user_id=str(self.user_id),\n            session_id=self.graph.session_id or self.session_id,\n        )\n"
              },
              "flow_name_selected": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Flow Name",
                "dynamic": false,
                "info": "The name of the flow to run.",
                "name": "flow_name_selected",
                "options": [],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Get context from files"
              },
              "session_id": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID to run the flow in.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": {
                  "data": {
                    "files": [],
                    "text": "",
                    "timestamp": "2025-03-04 09:26:02 UTC"
                  },
                  "default_value": "",
                  "text_key": "text"
                }
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RunFlow"
        },
        "dragging": false,
        "id": "RunFlow-OqJHt",
        "measured": {
          "height": 435,
          "width": 320
        },
        "position": {
          "x": 3417.205762801653,
          "y": 2495.7346929393643
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-b69hZ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Use as a template to create your own component.",
            "display_name": "Custom Component",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "code",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "method": "build_output",
                "name": "output",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"This is a custom component Input\",\n            value=\"Hello, World!\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        data = Data(value=self.input_value)\n        self.status = data\n        return data\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Value",
                "dynamic": false,
                "info": "This is a custom component Input",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CustomComponent"
        },
        "dragging": false,
        "id": "CustomComponent-b69hZ",
        "measured": {
          "height": 250,
          "width": 320
        },
        "position": {
          "x": 2403.1715045823566,
          "y": 2553.6782284449
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-MwOz3",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if not isinstance(self.input_value, Data | DataFrame | Message | str | list):\n            msg = f\"Expected Data or DataFrame or Message or str, got {type(self.input_value).__name__}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-MwOz3",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 5056.621466515349,
          "y": 2352.415067052223
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "EnvExtractor-8LUE4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extract environment variables for DocSpace services",
            "display_name": "Environment Variables Extractor",
            "documentation": "",
            "edited": false,
            "field_order": [],
            "frozen": false,
            "icon": "settings",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "API Service",
                "method": "get_api_host",
                "name": "api_host",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Files Service",
                "method": "get_files_host",
                "name": "files_host",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Qdrant Service",
                "method": "get_qdrant_host",
                "name": "qdrant_host",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Qdrant Port",
                "method": "get_qdrant_port",
                "name": "qdrant_port",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nfrom langflow.custom import Component\nfrom langflow.io import Output\nfrom langflow.schema import Message\n\n\nclass EnvExtractorComponent(Component):\n    \"\"\"Component for extracting environment variables.\"\"\"\n\n    display_name: str = \"Environment Variables Extractor\"\n    description: str = \"Extract environment variables for DocSpace services\"\n    name: str = \"EnvExtractor\"\n    icon = \"settings\"\n\n    outputs = [\n        Output(\n            name=\"api_host\",\n            display_name=\"API Service\",\n            method=\"get_api_host\",\n        ),\n        Output(\n            name=\"files_host\",\n            display_name=\"Files Service\",\n            method=\"get_files_host\",\n        ),\n        Output(\n            name=\"qdrant_host\",\n            display_name=\"Qdrant Service\",\n            method=\"get_qdrant_host\",\n        ),\n        Output(\n            name=\"qdrant_port\",\n            display_name=\"Qdrant Port\",\n            method=\"get_qdrant_port\",\n        ),\n    ]\n\n    def get_api_host(self) -> Message:\n        \"\"\"\n        Get the API service host from environment variables.\n\n        Returns:\n            Message object containing the API host URL\n        \"\"\"\n        try:\n            api_host = os.environ.get(\n                'HOST_API_SERVICE', 'http://onlyoffice-api:5050')\n            return Message(text=api_host)\n        except Exception as e:\n            raise ValueError(f\"Error getting API host: {str(e)}\")\n\n    def get_files_host(self) -> Message:\n        \"\"\"\n        Get the Files service host from environment variables.\n\n        Returns:\n            Message object containing the Files host URL\n        \"\"\"\n        try:\n            files_host = os.environ.get(\n                'HOST_FILES_SERVICE', 'http://onlyoffice-files:5050')\n            return Message(text=files_host)\n        except Exception as e:\n            raise ValueError(f\"Error getting Files host: {str(e)}\")\n\n    def get_qdrant_host(self) -> Message:\n        \"\"\"\n        Get the Qdrant service host from environment variables.\n\n        Returns:\n            Message object containing the Qdrant host URL\n        \"\"\"\n        try:\n            qdrant_host = os.environ.get(\n                'HOST_QDRANT_SERVICE', 'onlyoffice-qdrant')\n            return Message(text=qdrant_host)\n        except Exception as e:\n            raise ValueError(f\"Error getting Qdrant host: {str(e)}\")\n            \n    def get_qdrant_port(self) -> Message:\n        \"\"\"\n        Get the Qdrant service port from environment variables.\n\n        Returns:\n            Message object containing the Qdrant port\n        \"\"\"\n        try:\n            qdrant_port = os.environ.get(\n                'HOST_QDRANT_PORT', '6333')\n            return Message(text=qdrant_port)\n        except Exception as e:\n            raise ValueError(f\"Error getting Qdrant port: {str(e)}\")\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "EnvExtractor"
        },
        "id": "EnvExtractor-8LUE4",
        "measured": {
          "height": 311,
          "width": 320
        },
        "position": {
          "x": -960,
          "y": 2280
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-SWisu",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Message History",
            "documentation": "",
            "edited": false,
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "method": "retrieve_messages",
                "name": "messages",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "retrieve_messages_as_text",
                "name": "messages_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs import HandleInput\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import aget_messages\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n    ]\n\n    async def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = await aget_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-SWisu",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": -121.78966076071609,
          "y": 2778.768587763562
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RagPrompt-SR3ZC",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a structured RAG prompt with document context for retrieval-augmented generation.",
            "display_name": "RAG Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "document_context",
              "memory"
            ],
            "frozen": false,
            "icon": "file-text",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "RAG Prompt",
                "method": "format_rag_prompt",
                "name": "rag_prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema.message import Message\n\nRAG_PROMPT = \"\"\" \nDOCUMENTS:\n{document}\n\nHISTORY:\n{memory}\n\nINSTRUCTIONS:\nAnswer the users QUESTION using the DOCUMENTS text above.\nKeep your answer ground in the facts of the DOCUMENTS.\nIf the DOCUMENTS doesn't contain the facts to answer the QUESTION return 'Not known'\nPrefer use DOCUMENTS. If DOCUMENTS are empty or not contain answer - use HISTORY.\n\"\"\"\n\n\nclass RagPromptComponent(Component):\n    \"\"\"\n    Component that formats a RAG prompt with document context.\n    Creates a structured prompt for retrieval-augmented generation.\n    \"\"\"\n\n    display_name = \"RAG Prompt\"\n    description = \"Creates a structured RAG prompt with document context for retrieval-augmented generation.\"\n    icon = \"file-text\"\n    name = \"RagPrompt\"\n\n    inputs = [\n        MessageInput(\n            name=\"document_context\",\n            display_name=\"Document context\",\n            info=\"The context of the document to combine with others\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"memory\",\n            display_name=\"Chat memory\",\n            info=\"Chat memory\"\n        )\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"RAG Prompt\",\n            name=\"rag_prompt\",\n            method=\"format_rag_prompt\",\n        ),\n    ]\n\n    def format_rag_prompt(self) -> Message:\n        \"\"\"\n        Formats a RAG prompt with the provided document context.\n\n        Returns:\n            Message: A message containing the formatted RAG prompt\n        \"\"\"\n        # Get the document context\n        doc_msg = self.document_context\n        document_content = doc_msg.get_text() if doc_msg else \"\"\n\n        # Format the RAG prompt template with the document context\n        formatted_prompt = RAG_PROMPT.format(\n            document=document_content, memory=self.memory.get_text())\n\n        # Create a new message with the formatted prompt\n        # Preserve metadata from the document context message\n        rag_prompt_msg = Message(\n            text=formatted_prompt,\n            sender=doc_msg.sender if doc_msg else None,\n            sender_name=doc_msg.sender_name if doc_msg else None,\n            session_id=doc_msg.session_id if doc_msg else None,\n            flow_id=doc_msg.flow_id if doc_msg else None,\n        )\n\n        return rag_prompt_msg\n"
              },
              "document_context": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Document context",
                "dynamic": false,
                "info": "The context of the document to combine with others",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "document_context",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "memory": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Chat memory",
                "dynamic": false,
                "info": "Chat memory",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RagPrompt"
        },
        "dragging": false,
        "id": "RagPrompt-SR3ZC",
        "measured": {
          "height": 352,
          "width": 320
        },
        "position": {
          "x": 3864.2955039163085,
          "y": 2685.019221942129
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "InputParser-lGm6i",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Parse an input and return a parsed data object.",
            "display_name": "Parse input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed data",
                "method": "parse_input",
                "name": "parsed_data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\n\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import MessageInput\nfrom langflow.io import Output\nfrom langflow.schema import Data, Message\n\n\nclass InputParserComponent(Component):\n    display_name: str = \"Parse input\"\n    description: str = \"Parse an input and return a parsed data object.\"\n    name: str = \"InputParser\"\n    icon = \"braces\"\n\n    inputs = [\n        MessageInput(\n            name=\"input\",\n            display_name=\"Input\",\n            info=\"User input to parse\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Parsed data\",\n               name=\"parsed_data\", method=\"parse_input\"),\n    ]\n\n    def parse_input(self) -> Data:\n        \"\"\"Parse input text to extract references.\n\n        References can be in the following formats:\n        - @123 (file ID)\n        - @folder-123 (folder ID)\n        - References can appear anywhere in the text\n\n        Returns:\n            Data object with extracted references and text\n        \"\"\"\n        try:\n            # Get text from input Message object\n            input_message: Message = self.input\n\n            text = input_message.get_text()\n            if not isinstance(text, str) or not text:\n                return Data(data={})\n\n            # Define regex patterns for file and folder references\n            file_pattern = r'@(\\d+)'  # Matches @123 (file ID)\n            folder_pattern = r'@folder-(\\d+)'  # Matches @folder-123 (folder ID)\n            \n            # Extract all references\n            file_refs = re.findall(file_pattern, text)\n            folder_refs = re.findall(folder_pattern, text)\n            \n            # Combine all references\n            references = file_refs + [f\"folder-{ref}\" for ref in folder_refs]\n            \n            # Remove references from text if they are at the beginning\n            # This maintains backward compatibility with the old format\n            cleaned_text = text\n            parts = text.split(' ', 1)\n            if parts[0].startswith('@'):\n                cleaned_text = parts[1] if len(parts) > 1 else ''\n            \n            result = {\n                \"references\": references,\n                \"text\": cleaned_text,\n                \"original_text\": text\n            }\n\n            return Data(data=result)\n\n        except Exception as e:\n            raise Exception(f\"Error parsing input: {str(e)}\")\n"
              },
              "input": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "User input to parse",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "InputParser"
        },
        "dragging": false,
        "id": "InputParser-lGm6i",
        "measured": {
          "height": 250,
          "width": 320
        },
        "position": {
          "x": -243.84494902273738,
          "y": 1091.6570562038396
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-nFwIp",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-nFwIp",
        "measured": {
          "height": 656,
          "width": 320
        },
        "position": {
          "x": 1507.0606753929126,
          "y": 2135.157089709759
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-Ral8S",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-Ral8S",
        "measured": {
          "height": 656,
          "width": 320
        },
        "position": {
          "x": 4456.927202575749,
          "y": 1873.1353582530633
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-cNRSz",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-cNRSz",
        "measured": {
          "height": 656,
          "width": 320
        },
        "position": {
          "x": 2719.317618637456,
          "y": 801.0655433081632
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-xiNof",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if not isinstance(self.input_value, Data | DataFrame | Message | str | list):\n            msg = f\"Expected Data or DataFrame or Message or str, got {type(self.input_value).__name__}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-xiNof",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 3114.9619982268146,
          "y": 1162.2698125896175
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 195.76593037111115,
      "y": -153.34064952950496,
      "zoom": 0.40704032625810527
    }
  },
  "description": "Chain the Words, Master Language!",
  "endpoint_name": null,
  "folder_id": "75587cbc-6526-4bc3-a1ea-161a0baa475d",
  "gradient": null,
  "icon": null,
  "icon_bg_color": null,
  "id": "4e47f870-1b5f-4ce3-8bef-7256c78007ad",
  "is_component": false,
  "locked": false,
  "name": "DocSpace chat",
  "tags": null,
  "updated_at": "2025-03-18T07:27:36+00:00",
  "user_id": "c7e96ef2-ec8a-49e4-8883-d50f44f53acc",
  "webhook": false
}