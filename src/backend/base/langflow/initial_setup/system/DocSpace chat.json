{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TogetherAIModel",
            "id": "TogetherAIModel-Qfvv7",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-tjfon",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TogetherAIModel-Qfvv7{œdataTypeœ:œTogetherAIModelœ,œidœ:œTogetherAIModel-Qfvv7œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-tjfon{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-tjfonœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "TogetherAIModel-Qfvv7",
        "sourceHandle": "{œdataTypeœ: œTogetherAIModelœ, œidœ: œTogetherAIModel-Qfvv7œ, œnameœ: œtext_outputœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ChatOutput-tjfon",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œChatOutput-tjfonœ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-CUNeM",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "ParseReferences-wn59Q",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-CUNeM{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-CUNeMœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œDataœ]}-ParseReferences-wn59Q{œfieldNameœ:œinputœ,œidœ:œParseReferences-wn59Qœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "ConditionalRouter-CUNeM",
        "sourceHandle": "{œdataTypeœ: œConditionalRouterœ, œidœ: œConditionalRouter-CUNeMœ, œnameœ: œtrue_resultœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ParseReferences-wn59Q",
        "targetHandle": "{œfieldNameœ: œinputœ, œidœ: œParseReferences-wn59Qœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-4jjfR",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-aUjPm~input_value",
            "id": "RunFlow-TnxpB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-4jjfR{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-4jjfRœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-RunFlow-TnxpB{œfieldNameœ:œTextInput-aUjPm~input_valueœ,œidœ:œRunFlow-TnxpBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ConditionalRouter-4jjfR",
        "sourceHandle": "{œdataTypeœ: œConditionalRouterœ, œidœ: œConditionalRouter-4jjfRœ, œnameœ: œtrue_resultœ, œoutput_typesœ: [œMessageœ]}",
        "target": "RunFlow-TnxpB",
        "targetHandle": "{œfieldNameœ: œTextInput-aUjPm~input_valueœ, œidœ: œRunFlow-TnxpBœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-OvpRl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-e6brU~input_value",
            "id": "RunFlow-TnxpB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-OvpRl{œdataTypeœ:œTextInputœ,œidœ:œTextInput-OvpRlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-RunFlow-TnxpB{œfieldNameœ:œTextInput-e6brU~input_valueœ,œidœ:œRunFlow-TnxpBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "TextInput-OvpRl",
        "sourceHandle": "{œdataTypeœ: œTextInputœ, œidœ: œTextInput-OvpRlœ, œnameœ: œtextœ, œoutput_typesœ: [œMessageœ]}",
        "target": "RunFlow-TnxpB",
        "targetHandle": "{œfieldNameœ: œTextInput-e6brU~input_valueœ, œidœ: œRunFlow-TnxpBœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseReferences",
            "id": "ParseReferences-wn59Q",
            "name": "parsed_references",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "TextInput-OvpRl",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParseReferences-wn59Q{œdataTypeœ:œParseReferencesœ,œidœ:œParseReferences-wn59Qœ,œnameœ:œparsed_referencesœ,œoutput_typesœ:[œDataœ]}-TextInput-OvpRl{œfieldNameœ:œdataœ,œidœ:œTextInput-OvpRlœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "ParseReferences-wn59Q",
        "sourceHandle": "{œdataTypeœ: œParseReferencesœ, œidœ: œParseReferences-wn59Qœ, œnameœ: œparsed_referencesœ, œoutput_typesœ: [œDataœ]}",
        "target": "TextInput-OvpRl",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œTextInput-OvpRlœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseReferences",
            "id": "ParseReferences-wn59Q",
            "name": "parsed_references",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "GetFilesFromFolders-BWaG7",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParseReferences-wn59Q{œdataTypeœ:œParseReferencesœ,œidœ:œParseReferences-wn59Qœ,œnameœ:œparsed_referencesœ,œoutput_typesœ:[œDataœ]}-GetFilesFromFolders-BWaG7{œfieldNameœ:œdataœ,œidœ:œGetFilesFromFolders-BWaG7œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "ParseReferences-wn59Q",
        "sourceHandle": "{œdataTypeœ: œParseReferencesœ, œidœ: œParseReferences-wn59Qœ, œnameœ: œparsed_referencesœ, œoutput_typesœ: [œDataœ]}",
        "target": "GetFilesFromFolders-BWaG7",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œGetFilesFromFolders-BWaG7œ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GetFilesFromFolders",
            "id": "GetFilesFromFolders-BWaG7",
            "name": "files",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ConditionalRouter-4jjfR",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-GetFilesFromFolders-BWaG7{œdataTypeœ:œGetFilesFromFoldersœ,œidœ:œGetFilesFromFolders-BWaG7œ,œnameœ:œfilesœ,œoutput_typesœ:[œDataœ]}-ConditionalRouter-4jjfR{œfieldNameœ:œdataœ,œidœ:œConditionalRouter-4jjfRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "GetFilesFromFolders-BWaG7",
        "sourceHandle": "{œdataTypeœ: œGetFilesFromFoldersœ, œidœ: œGetFilesFromFolders-BWaG7œ, œnameœ: œfilesœ, œoutput_typesœ: [œDataœ]}",
        "target": "ConditionalRouter-4jjfR",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œConditionalRouter-4jjfRœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RunFlow",
            "id": "RunFlow-TnxpB",
            "name": "flow_outputs_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "document_context",
            "id": "RagPrompt-vGvXR",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RunFlow-TnxpB{œdataTypeœ:œRunFlowœ,œidœ:œRunFlow-TnxpBœ,œnameœ:œflow_outputs_messageœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-vGvXR{œfieldNameœ:œdocument_contextœ,œidœ:œRagPrompt-vGvXRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RunFlow-TnxpB",
        "sourceHandle": "{œdataTypeœ: œRunFlowœ, œidœ: œRunFlow-TnxpBœ, œnameœ: œflow_outputs_messageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "RagPrompt-vGvXR",
        "targetHandle": "{œfieldNameœ: œdocument_contextœ, œidœ: œRagPrompt-vGvXRœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RagPrompt",
            "id": "RagPrompt-vGvXR",
            "name": "rag_prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "TogetherAIModel-Qfvv7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-RagPrompt-vGvXR{œdataTypeœ:œRagPromptœ,œidœ:œRagPrompt-vGvXRœ,œnameœ:œrag_promptœ,œoutput_typesœ:[œMessageœ]}-TogetherAIModel-Qfvv7{œfieldNameœ:œsystem_messageœ,œidœ:œTogetherAIModel-Qfvv7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RagPrompt-vGvXR",
        "sourceHandle": "{œdataTypeœ: œRagPromptœ, œidœ: œRagPrompt-vGvXRœ, œnameœ: œrag_promptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "TogetherAIModel-Qfvv7",
        "targetHandle": "{œfieldNameœ: œsystem_messageœ, œidœ: œTogetherAIModel-Qfvv7œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-z5Y8m",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "GetFoldersContent-APjkO",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TextInput-z5Y8m{œdataTypeœ:œTextInputœ,œidœ:œTextInput-z5Y8mœ,œnameœ:œtextœ,œoutput_typesœ:[œDataœ]}-GetFoldersContent-APjkO{œfieldNameœ:œdataœ,œidœ:œGetFoldersContent-APjkOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "TextInput-z5Y8m",
        "sourceHandle": "{œdataTypeœ: œTextInputœ, œidœ: œTextInput-z5Y8mœ, œnameœ: œtextœ, œoutput_typesœ: [œMessageœ]}",
        "target": "GetFoldersContent-APjkO",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œGetFoldersContent-APjkOœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GetFoldersContent",
            "id": "GetFoldersContent-APjkO",
            "name": "folder_content",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "document_context",
            "id": "SystemPrompt-cM1BX",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-GetFoldersContent-APjkO{œdataTypeœ:œGetFoldersContentœ,œidœ:œGetFoldersContent-APjkOœ,œnameœ:œfolder_contentœ,œoutput_typesœ:[œDataœ]}-SystemPrompt-cM1BX{œfieldNameœ:œdocument_contextœ,œidœ:œSystemPrompt-cM1BXœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "GetFoldersContent-APjkO",
        "sourceHandle": "{œdataTypeœ: œGetFoldersContentœ, œidœ: œGetFoldersContent-APjkOœ, œnameœ: œfolder_contentœ, œoutput_typesœ: [œDataœ]}",
        "target": "SystemPrompt-cM1BX",
        "targetHandle": "{œfieldNameœ: œdocument_contextœ, œidœ: œSystemPrompt-cM1BXœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SystemPrompt",
            "id": "SystemPrompt-cM1BX",
            "name": "system_prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "ToolCallingAgent-U12uF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-SystemPrompt-cM1BX{œdataTypeœ:œSystemPromptœ,œidœ:œSystemPrompt-cM1BXœ,œnameœ:œsystem_promptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-U12uF{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-U12uFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "SystemPrompt-cM1BX",
        "sourceHandle": "{œdataTypeœ: œSystemPromptœ, œidœ: œSystemPrompt-cM1BXœ, œnameœ: œsystem_promptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ToolCallingAgent-U12uF",
        "targetHandle": "{œfieldNameœ: œsystem_promptœ, œidœ: œToolCallingAgent-U12uFœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TogetherAIModel",
            "id": "TogetherAIModel-i6idC",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "ToolCallingAgent-U12uF",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TogetherAIModel-i6idC{œdataTypeœ:œTogetherAIModelœ,œidœ:œTogetherAIModel-i6idCœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-U12uF{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-U12uFœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "source": "TogetherAIModel-i6idC",
        "sourceHandle": "{œdataTypeœ: œTogetherAIModelœ, œidœ: œTogetherAIModel-i6idCœ, œnameœ: œmodel_outputœ, œoutput_typesœ: [œLanguageModelœ]}",
        "target": "ToolCallingAgent-U12uF",
        "targetHandle": "{œfieldNameœ: œllmœ, œidœ: œToolCallingAgent-U12uFœ, œinputTypesœ: [œLanguageModelœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OnlyofficeDocspaceFolderListDocuments",
            "id": "OnlyofficeDocspaceFolderListDocuments-6gGL6",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-U12uF",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OnlyofficeDocspaceFolderListDocuments-6gGL6{œdataTypeœ:œOnlyofficeDocspaceFolderListDocumentsœ,œidœ:œOnlyofficeDocspaceFolderListDocuments-6gGL6œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-U12uF{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-U12uFœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OnlyofficeDocspaceFolderListDocuments-6gGL6",
        "sourceHandle": "{œdataTypeœ: œOnlyofficeDocspaceFolderListDocumentsœ, œidœ: œOnlyofficeDocspaceFolderListDocuments-6gGL6œ, œnameœ: œapi_build_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "ToolCallingAgent-U12uF",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œToolCallingAgent-U12uFœ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ToolCallingAgent",
            "id": "ToolCallingAgent-U12uF",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-TPR8t",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ToolCallingAgent-U12uF{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-U12uFœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-TPR8t{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-TPR8tœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ToolCallingAgent-U12uF",
        "sourceHandle": "{œdataTypeœ: œToolCallingAgentœ, œidœ: œToolCallingAgent-U12uFœ, œnameœ: œresponseœ, œoutput_typesœ: [œMessageœ]}",
        "target": "CustomComponent-TPR8t",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œCustomComponent-TPR8tœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-TPR8t",
            "name": "output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-aUjPm~input_value",
            "id": "RunFlow-PBB3K",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-CustomComponent-TPR8t{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-TPR8tœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-RunFlow-PBB3K{œfieldNameœ:œTextInput-aUjPm~input_valueœ,œidœ:œRunFlow-PBB3Kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "CustomComponent-TPR8t",
        "sourceHandle": "{œdataTypeœ: œCustomComponentœ, œidœ: œCustomComponent-TPR8tœ, œnameœ: œoutputœ, œoutput_typesœ: [œDataœ]}",
        "target": "RunFlow-PBB3K",
        "targetHandle": "{œfieldNameœ: œTextInput-aUjPm~input_valueœ, œidœ: œRunFlow-PBB3Kœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-hcS64",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TogetherAIModel-YLhJ2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-hcS64{œdataTypeœ:œChatInputœ,œidœ:œChatInput-hcS64œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-TogetherAIModel-YLhJ2{œfieldNameœ:œinput_valueœ,œidœ:œTogetherAIModel-YLhJ2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-hcS64",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-hcS64œ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "TogetherAIModel-YLhJ2",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œTogetherAIModel-YLhJ2œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TogetherAIModel",
            "id": "TogetherAIModel-YLhJ2",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-4t5Zg",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TogetherAIModel-YLhJ2{œdataTypeœ:œTogetherAIModelœ,œidœ:œTogetherAIModel-YLhJ2œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-4t5Zg{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4t5Zgœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "source": "TogetherAIModel-YLhJ2",
        "sourceHandle": "{œdataTypeœ: œTogetherAIModelœ, œidœ: œTogetherAIModel-YLhJ2œ, œnameœ: œtext_outputœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ChatOutput-4t5Zg",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œChatOutput-4t5Zgœ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-CUNeM",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ToolCallingAgent-U12uF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-CUNeM{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-CUNeMœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-U12uF{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-U12uFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ConditionalRouter-CUNeM",
        "sourceHandle": "{œdataTypeœ: œConditionalRouterœ, œidœ: œConditionalRouter-CUNeMœ, œnameœ: œfalse_resultœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ToolCallingAgent-U12uF",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œToolCallingAgent-U12uFœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-CUNeM",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-e6brU~input_value",
            "id": "RunFlow-PBB3K",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-CUNeM{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-CUNeMœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-RunFlow-PBB3K{œfieldNameœ:œTextInput-e6brU~input_valueœ,œidœ:œRunFlow-PBB3Kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ConditionalRouter-CUNeM",
        "sourceHandle": "{œdataTypeœ: œConditionalRouterœ, œidœ: œConditionalRouter-CUNeMœ, œnameœ: œfalse_resultœ, œoutput_typesœ: [œMessageœ]}",
        "target": "RunFlow-PBB3K",
        "targetHandle": "{œfieldNameœ: œTextInput-e6brU~input_valueœ, œidœ: œRunFlow-PBB3Kœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "EnvExtractor",
            "id": "EnvExtractor-picCE",
            "name": "files_host",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "files_host",
            "id": "GetFoldersContent-APjkO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__EnvExtractor-picCE{œdataTypeœ:œEnvExtractorœ,œidœ:œEnvExtractor-picCEœ,œnameœ:œfiles_hostœ,œoutput_typesœ:[œMessageœ]}-GetFoldersContent-APjkO{œfieldNameœ:œfiles_hostœ,œidœ:œGetFoldersContent-APjkOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "EnvExtractor-picCE",
        "sourceHandle": "{œdataTypeœ: œEnvExtractorœ, œidœ: œEnvExtractor-picCEœ, œnameœ: œfiles_hostœ, œoutput_typesœ: [œMessageœ]}",
        "target": "GetFoldersContent-APjkO",
        "targetHandle": "{œfieldNameœ: œfiles_hostœ, œidœ: œGetFoldersContent-APjkOœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-OvpRl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TogetherAIModel-Qfvv7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-OvpRl{œdataTypeœ:œTextInputœ,œidœ:œTextInput-OvpRlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TogetherAIModel-Qfvv7{œfieldNameœ:œinput_valueœ,œidœ:œTogetherAIModel-Qfvv7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "TextInput-OvpRl",
        "sourceHandle": "{œdataTypeœ: œTextInputœ, œidœ: œTextInput-OvpRlœ, œnameœ: œtextœ, œoutput_typesœ: [œMessageœ]}",
        "target": "TogetherAIModel-Qfvv7",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œTogetherAIModel-Qfvv7œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OnlyofficeDocspaceFolderListDocuments",
            "id": "OnlyofficeDocspaceFolderListDocuments-Y61FS",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-U12uF",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OnlyofficeDocspaceFolderListDocuments-Y61FS{œdataTypeœ:œOnlyofficeDocspaceFolderListDocumentsœ,œidœ:œOnlyofficeDocspaceFolderListDocuments-Y61FSœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-U12uF{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-U12uFœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "source": "OnlyofficeDocspaceFolderListDocuments-Y61FS",
        "sourceHandle": "{œdataTypeœ: œOnlyofficeDocspaceFolderListDocumentsœ, œidœ: œOnlyofficeDocspaceFolderListDocuments-Y61FSœ, œnameœ: œapi_build_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "ToolCallingAgent-U12uF",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œToolCallingAgent-U12uFœ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-dsE8e",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "memory",
            "id": "SystemPrompt-cM1BX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Memory-dsE8e{œdataTypeœ:œMemoryœ,œidœ:œMemory-dsE8eœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-SystemPrompt-cM1BX{œfieldNameœ:œmemoryœ,œidœ:œSystemPrompt-cM1BXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Memory-dsE8e",
        "sourceHandle": "{œdataTypeœ: œMemoryœ, œidœ: œMemory-dsE8eœ, œnameœ: œmessages_textœ, œoutput_typesœ: [œMessageœ]}",
        "target": "SystemPrompt-cM1BX",
        "targetHandle": "{œfieldNameœ: œmemoryœ, œidœ: œSystemPrompt-cM1BXœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-dsE8e",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "memory",
            "id": "RagPrompt-vGvXR",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Memory-dsE8e{œdataTypeœ:œMemoryœ,œidœ:œMemory-dsE8eœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-vGvXR{œfieldNameœ:œmemoryœ,œidœ:œRagPrompt-vGvXRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Memory-dsE8e",
        "sourceHandle": "{œdataTypeœ: œMemoryœ, œidœ: œMemory-dsE8eœ, œnameœ: œmessages_textœ, œoutput_typesœ: [œMessageœ]}",
        "target": "RagPrompt-vGvXR",
        "targetHandle": "{œfieldNameœ: œmemoryœ, œidœ: œRagPrompt-vGvXRœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RunFlow",
            "id": "RunFlow-PBB3K",
            "name": "flow_outputs_message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "document_context",
            "id": "RagPrompt-pvny9",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__RunFlow-PBB3K{œdataTypeœ:œRunFlowœ,œidœ:œRunFlow-PBB3Kœ,œnameœ:œflow_outputs_messageœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-pvny9{œfieldNameœ:œdocument_contextœ,œidœ:œRagPrompt-pvny9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RunFlow-PBB3K",
        "sourceHandle": "{œdataTypeœ: œRunFlowœ, œidœ: œRunFlow-PBB3Kœ, œnameœ: œflow_outputs_messageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "RagPrompt-pvny9",
        "targetHandle": "{œfieldNameœ: œdocument_contextœ, œidœ: œRagPrompt-pvny9œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-dsE8e",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "memory",
            "id": "RagPrompt-pvny9",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Memory-dsE8e{œdataTypeœ:œMemoryœ,œidœ:œMemory-dsE8eœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-RagPrompt-pvny9{œfieldNameœ:œmemoryœ,œidœ:œRagPrompt-pvny9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Memory-dsE8e",
        "sourceHandle": "{œdataTypeœ: œMemoryœ, œidœ: œMemory-dsE8eœ, œnameœ: œmessages_textœ, œoutput_typesœ: [œMessageœ]}",
        "target": "RagPrompt-pvny9",
        "targetHandle": "{œfieldNameœ: œmemoryœ, œidœ: œRagPrompt-pvny9œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RagPrompt",
            "id": "RagPrompt-pvny9",
            "name": "rag_prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "TogetherAIModel-YLhJ2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__RagPrompt-pvny9{œdataTypeœ:œRagPromptœ,œidœ:œRagPrompt-pvny9œ,œnameœ:œrag_promptœ,œoutput_typesœ:[œMessageœ]}-TogetherAIModel-YLhJ2{œfieldNameœ:œsystem_messageœ,œidœ:œTogetherAIModel-YLhJ2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "RagPrompt-pvny9",
        "sourceHandle": "{œdataTypeœ: œRagPromptœ, œidœ: œRagPrompt-pvny9œ, œnameœ: œrag_promptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "TogetherAIModel-YLhJ2",
        "targetHandle": "{œfieldNameœ: œsystem_messageœ, œidœ: œTogetherAIModel-YLhJ2œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-hcS64",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input",
            "id": "InputParser-iyYS7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-hcS64{œdataTypeœ:œChatInputœ,œidœ:œChatInput-hcS64œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-InputParser-iyYS7{œfieldNameœ:œinputœ,œidœ:œInputParser-iyYS7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-hcS64",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-hcS64œ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "InputParser-iyYS7",
        "targetHandle": "{œfieldNameœ: œinputœ, œidœ: œInputParser-iyYS7œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "InputParser",
            "id": "InputParser-iyYS7",
            "name": "parsed_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ConditionalRouter-CUNeM",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__InputParser-iyYS7{œdataTypeœ:œInputParserœ,œidœ:œInputParser-iyYS7œ,œnameœ:œparsed_dataœ,œoutput_typesœ:[œDataœ]}-ConditionalRouter-CUNeM{œfieldNameœ:œdataœ,œidœ:œConditionalRouter-CUNeMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "InputParser-iyYS7",
        "sourceHandle": "{œdataTypeœ: œInputParserœ, œidœ: œInputParser-iyYS7œ, œnameœ: œparsed_dataœ, œoutput_typesœ: [œDataœ]}",
        "target": "ConditionalRouter-CUNeM",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œConditionalRouter-CUNeMœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ChatInput-hcS64",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-hcS64",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": -575.6915469030305,
          "y": 923.6702876399132
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TogetherAIModel-Qfvv7",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using TogetherAI LLMs.",
            "display_name": "TogetherAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "togetherai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "TogetherAI",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "TogetherAI API Key",
                "dynamic": false,
                "info": "The TogetherAI API Key to use for the TogetherAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "togetherai_api_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langchain_openai import ChatOpenAI\nfrom langchain_together import ChatTogether\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\n#from langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.base.models.togetherai_constants import TOGETHERAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass TogetherAIModelComponent(LCModelComponent):\n    display_name = \"TogetherAI\"\n    description = \"Generates text using TogetherAI LLMs.\"\n    icon = \"TogetherAI\"\n    name = \"TogetherAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=TOGETHERAI_MODEL_NAMES,\n            value=TOGETHERAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"togetherai_api_base\",\n            display_name=\"TogetherAI API Base\",\n            advanced=True,\n            info=\"The base URL of the TogetherAI API. \"\n            \"Defaults to https://api.together.xyz/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"TogetherAI API Key\",\n            info=\"The TogetherAI API Key to use for the TogetherAI model.\",\n            advanced=False,\n            value=\"TOGETHERAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to TogetherAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        togetherai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        togetherai_api_base = self.togetherai_api_base or \"https://api.together.xyz/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(togetherai_api_key).get_secret_value() if togetherai_api_key else None\n        output = ChatTogether(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=togetherai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an TogetherAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        # try:\n        #     from openai import BadRequestError\n        # except ImportError:\n        #     return None\n        # if isinstance(e, BadRequestError):\n        #     message = e.body.get(\"message\")\n        #     if message:\n        #         return message\n        return e\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
                  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to TogetherAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "togetherai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "TogetherAI API Base",
                "dynamic": false,
                "info": "The base URL of the TogetherAI API. Defaults to https://api.together.xyz/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "togetherai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TogetherAIModel"
        },
        "dragging": false,
        "id": "TogetherAIModel-Qfvv7",
        "measured": {
          "height": 656,
          "width": 320
        },
        "position": {
          "x": 2660.2976060883316,
          "y": 683.359841130292
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-tjfon",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if not isinstance(self.input_value, Data | DataFrame | Message | str | list):\n            msg = f\"Expected Data or DataFrame or Message or str, got {type(self.input_value).__name__}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-tjfon",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 3088.7137436238254,
          "y": 933.3109852349642
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-CUNeM",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "method": "true_response",
                "name": "true_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "method": "false_response",
                "name": "false_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-CUNeM",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 222.71115461619974,
          "y": 1096.0079008216633
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RunFlow-TnxpB",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a tool component from a Flow that takes all its inputs and runs it.  \n **Select a Flow to use the tool mode**",
            "display_name": "Run Flow",
            "documentation": "",
            "edited": false,
            "field_order": [
              "flow_name_selected",
              "session_id"
            ],
            "frozen": false,
            "icon": "Workflow",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Data Output",
                "hidden": true,
                "method": "data_output",
                "name": "flow_outputs_data",
                "required_inputs": [],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Dataframe Output",
                "hidden": true,
                "method": "dataframe_output",
                "name": "flow_outputs_dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Message Output",
                "method": "message_output",
                "name": "flow_outputs_message",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom loguru import logger\n\nfrom langflow.base.tools.run_flow import RunFlowBaseComponent\nfrom langflow.helpers.flow import run_flow\nfrom langflow.schema import dotdict\n\n\nclass RunFlowComponent(RunFlowBaseComponent):\n    display_name = \"Run Flow\"\n    description = (\n        \"Creates a tool component from a Flow that takes all its inputs and runs it. \"\n        \" \\n **Select a Flow to use the tool mode**\"\n    )\n    beta = True\n    name = \"RunFlow\"\n    icon = \"Workflow\"\n\n    inputs = RunFlowBaseComponent._base_inputs\n    outputs = RunFlowBaseComponent._base_outputs\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name_selected\":\n            build_config[\"flow_name_selected\"][\"options\"] = await self.get_flow_names()\n            missing_keys = [key for key in self.default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n            if field_value is not None:\n                try:\n                    graph = await self.get_graph(field_value)\n                    build_config = self.update_build_config_from_graph(build_config, graph)\n                except Exception as e:\n                    msg = f\"Error building graph for flow {field_value}\"\n                    logger.exception(msg)\n                    raise RuntimeError(msg) from e\n        return build_config\n\n    async def run_flow_with_tweaks(self):\n        tweaks: dict = {}\n\n        flow_name_selected = self._attributes.get(\"flow_name_selected\")\n        parsed_flow_tweak_data = self._attributes.get(\"flow_tweak_data\", {})\n        if not isinstance(parsed_flow_tweak_data, dict):\n            parsed_flow_tweak_data = parsed_flow_tweak_data.dict()\n\n        if parsed_flow_tweak_data != {}:\n            for field in parsed_flow_tweak_data:\n                if \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = parsed_flow_tweak_data[field]\n        else:\n            for field in self._attributes:\n                if field not in self.default_keys and \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = self._attributes[field]\n\n        return await run_flow(\n            inputs=None,\n            output_type=\"all\",\n            flow_id=None,\n            flow_name=flow_name_selected,\n            tweaks=tweaks,\n            user_id=str(self.user_id),\n            session_id=self.graph.session_id or self.session_id,\n        )\n"
              },
              "flow_name_selected": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Flow Name",
                "dynamic": false,
                "info": "The name of the flow to run.",
                "name": "flow_name_selected",
                "options": [],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Get context from files"
              },
              "session_id": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID to run the flow in.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": {
                  "data": {
                    "files": [],
                    "text": "",
                    "timestamp": "2025-03-04 09:26:02 UTC"
                  },
                  "default_value": "",
                  "text_key": "text"
                }
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RunFlow"
        },
        "dragging": false,
        "id": "RunFlow-TnxpB",
        "measured": {
          "height": 435,
          "width": 320
        },
        "position": {
          "x": 1874.0153737048265,
          "y": 896.2158054420645
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseReferences-wn59Q",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Parse references from input data to extract files, folders, and flags.",
            "display_name": "Parse References",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed references",
                "method": "parse_references",
                "name": "parsed_references",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List, Dict, Any, Union\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DataInput\nfrom langflow.io import Output\nfrom langflow.schema import Data, Message\n\n\nclass ReferencesParserComponent(Component):\n    display_name: str = \"Parse References\"\n    description: str = \"Parse references from input data to extract files, folders, and flags.\"\n    name: str = \"ParseReferences\"\n    icon = \"braces\"\n\n    inputs = [\n        DataInput(\n            name=\"input\",\n            display_name=\"Data\",\n            info=\"Input data containing references\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Parsed references\",\n               name=\"parsed_references\", method=\"parse_references\"),\n    ]\n\n    def parse_references(self) -> Data:\n        \"\"\"Parse input data to extract and categorize references.\n\n        Sorts input array into:\n        - files: numeric IDs as integers\n        - folders: folder numbers extracted from 'folder-X' format\n        - docspace_api: True if 'docspace-api' is in the input\n        - docspace_sdk: True if 'docspace-sdk' is in the input\n\n        Returns:\n            Data: Parsed references with files, folders, and flags\n        \"\"\"\n        input_data = self.input.data\n\n        if not input_data:\n            return Data(data={\n                \"files\": [],\n                \"folders\": [],\n                \"docspace_api\": False,\n                \"docspace_sdk\": False\n            })\n\n        # Extract references from input\n        references = input_data.get(\"references\", [])\n\n        # Initialize result containers\n        files = []\n        folders = []\n        docspace_api = False\n        docspace_sdk = False\n\n        # Process each reference\n        for ref in references:\n            # Convert to string to handle different types\n            ref_str = str(ref).strip()\n\n            # Check if it's a file ID (numeric)\n            if ref_str.isdigit():\n                files.append(int(ref_str))\n            # Check if it's a folder reference\n            elif ref_str.startswith(\"folder-\"):\n                try:\n                    folder_id = int(ref_str.replace(\"folder-\", \"\"))\n                    folders.append(folder_id)\n                except ValueError:\n                    # Skip invalid folder format\n                    pass\n            # Check for docspace API/SDK flags\n            elif ref_str == \"docspace-api\":\n                docspace_api = True\n            elif ref_str == \"docspace-sdk\":\n                docspace_sdk = True\n\n        # Return structured data\n        return Data(data={\n            \"files\": files,\n            \"folders\": folders,\n            \"docspace_api\": docspace_api,\n            \"docspace_sdk\": docspace_sdk\n        })\n"
              },
              "input": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "Input data containing references",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseReferences"
        },
        "dragging": false,
        "id": "ParseReferences-wn59Q",
        "measured": {
          "height": 212,
          "width": 320
        },
        "position": {
          "x": 678.6053305529712,
          "y": 934.6952536665756
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-4jjfR",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else Files",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "method": "true_response",
                "name": "true_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "method": "false_response",
                "name": "false_result",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-4jjfR",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 1475.9805948811124,
          "y": 946.8405851261984
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-OvpRl",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get question from data.",
            "display_name": "Question",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-OvpRl",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": 1116.2054750408136,
          "y": 1296.6842518544854
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GetFilesFromFolders-BWaG7",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts files from DocSpace folders and returns their metadata including IDs, names, and content types",
            "display_name": "Get Files From Folders",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "asc_auth_key"
            ],
            "frozen": false,
            "icon": "file-search",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Files",
                "method": "get_files_from_folders",
                "name": "files",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asc_auth_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Auth key",
                "dynamic": false,
                "info": "Auth key to use",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "asc_auth_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "asc_auth_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import MessageInput, DataInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\n\n\nclass GetFilesFromFoldersComponent(Component):\n    \"\"\"Component for extracting files from DocSpace folders via API.\"\"\"\n\n    display_name: str = \"Get Files From Folders\"\n    description: str = \"Extracts files from DocSpace folders and returns their metadata including IDs, names, and content types\"\n    name: str = \"GetFilesFromFolders\"\n    icon = \"file-search\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Folders and Files IDs\",\n            info=\"IDs of the folders and files to get\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"asc_auth_key\",\n            display_name=\"Auth key\",\n            info=\"Auth key to use\",\n            required=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            name=\"files\",\n            display_name=\"Files\",\n            method=\"get_files_from_folders\",\n        ),\n    ]\n\n    async def get_folder(self, session: aiohttp.ClientSession, folder_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Make an async API request to get folder information from DocSpace.\n\n        Args:\n            session: aiohttp client session\n            folder_id: ID of the folder to retrieve\n\n        Returns:\n            Dict containing the folder information including metadata and contents\n        \"\"\"\n        try:\n            headers = {\n                'Authorization': self.asc_auth_key,\n            }\n\n            files_host = os.environ.get('HOST_FILES_SERVICE', 'http://onlyoffice-files:5050')\n            url = f'{files_host}/api/2.0/files/{folder_id}'\n\n            async with session.get(url, headers=headers, timeout=30) as response:\n                response.raise_for_status()\n                data = await response.json()\n                return data[\"response\"]\n\n        except Exception as e:\n            print(f\"Error getting folder {folder_id}: {str(e)}\")\n            return None\n\n    async def fetch_all_folders(self, folder_ids: List[str]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Fetch all folders concurrently using aiohttp for efficient retrieval.\n\n        Args:\n            folder_ids: List of folder IDs to fetch from DocSpace\n\n        Returns:\n            List of folder information dictionaries with complete metadata\n        \"\"\"\n        async with aiohttp.ClientSession() as session:\n            # Create tasks for all file fetches\n            tasks = [self.get_folder(session, folder_id)\n                     for folder_id in folder_ids]\n            # Wait for all tasks to complete (like Promise.all)\n            results = await asyncio.gather(*tasks)\n            # Filter out None results (failed requests)\n            return [r for r in results if r is not None]\n\n    async def get_files_from_folders(self) -> Data:\n        \"\"\"\n        Make concurrent API requests to retrieve folders from DocSpace and extract their files.\n        Processes the input folder IDs, fetches folder information, and extracts file metadata.\n\n        Returns:\n            Data object containing a list of file information dictionaries extracted from the folders\n        \"\"\"\n        try:\n            # Get folder IDs from input data\n            folders_data: List[str] = self.data.data.get(\n                \"folders\", [])\n            files_data: List[str] = self.data.data.get(\n                \"files\", [])\n\n            if not folders_data and not files_data:\n                return Data(data={\"files\": []})\n\n            if not folders_data:\n                return Data(data={\"files\": files_data})\n\n            # Fetch all folders concurrently\n            folders_info = await self.fetch_all_folders(folders_data)\n\n            # Extract files from all folders\n            files_info = []\n            for folder in folders_info:\n                if \"files\" in folder and isinstance(folder[\"files\"], list):\n                    files_info.extend(folder[\"files\"])\n\n            # Extract file IDs from folder files\n            folder_file_ids = [file.get('id', '')\n                               for file in files_info if file.get('id')]\n\n            # Merge with files_data and remove duplicates using a set\n            all_file_ids = set(folder_file_ids)\n            all_file_ids.update([file_id for file_id in files_data if file_id])\n\n            # Convert back to list\n            unique_files = list(all_file_ids)\n\n            return Data(data={\"files\": unique_files})\n\n        except Exception as e:\n            return Data(data={\"files\": []})\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Folders and Files IDs",
                "dynamic": false,
                "info": "IDs of the folders and files to get",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GetFilesFromFolders"
        },
        "dragging": false,
        "id": "GetFilesFromFolders-BWaG7",
        "measured": {
          "height": 314,
          "width": 320
        },
        "position": {
          "x": 1101.3936852683325,
          "y": 881.7143561599348
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-z5Y8m",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Current folder to start flow",
            "display_name": "Current folder",
            "documentation": "",
            "edited": false,
            "field_order": [
              "current_folder"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-z5Y8m",
        "measured": {
          "height": 230,
          "width": 320
        },
        "position": {
          "x": -809.1044146512302,
          "y": 1878.0130236846019
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RagPrompt-vGvXR",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a structured RAG prompt with document context for retrieval-augmented generation.",
            "display_name": "RAG Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "document_context",
              "memory"
            ],
            "frozen": false,
            "icon": "file-text",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "RAG Prompt",
                "method": "format_rag_prompt",
                "name": "rag_prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema.message import Message\n\nRAG_PROMPT = \"\"\" \nDOCUMENTS:\n{document}\n\nINSTRUCTIONS:\nAnswer the users QUESTION using the DOCUMENTS text above.\nKeep your answer ground in the facts of the DOCUMENTS.\nIf the DOCUMENTS doesn't contain the facts to answer the QUESTION return 'Not known'\n\"\"\"\n\n\nclass RagPromptComponent(Component):\n    \"\"\"\n    Component that formats a RAG prompt with document context.\n    Creates a structured prompt for retrieval-augmented generation.\n    \"\"\"\n\n    display_name = \"RAG Prompt\"\n    description = \"Creates a structured RAG prompt with document context for retrieval-augmented generation.\"\n    icon = \"file-text\"\n    name = \"RagPrompt\"\n\n    inputs = [\n        MessageInput(\n            name=\"document_context\",\n            display_name=\"Document context\",\n            info=\"The context of the document to combine with others\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"RAG Prompt\",\n            name=\"rag_prompt\",\n            method=\"format_rag_prompt\",\n        ),\n    ]\n\n    def format_rag_prompt(self) -> Message:\n        \"\"\"\n        Formats a RAG prompt with the provided document context.\n\n        Returns:\n            Message: A message containing the formatted RAG prompt\n        \"\"\"\n        # Get the document context\n        doc_msg = self.document_context\n        document_content = doc_msg.get_text() if doc_msg else \"\"\n\n        # Format the RAG prompt template with the document context\n        formatted_prompt = RAG_PROMPT.format(document=document_content)\n\n        # Create a new message with the formatted prompt\n        # Preserve metadata from the document context message\n        rag_prompt_msg = Message(\n            text=formatted_prompt,\n            sender=doc_msg.sender if doc_msg else None,\n            sender_name=doc_msg.sender_name if doc_msg else None,\n            session_id=doc_msg.session_id if doc_msg else None,\n            flow_id=doc_msg.flow_id if doc_msg else None,\n        )\n\n        return rag_prompt_msg\n"
              },
              "document_context": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Document context",
                "dynamic": false,
                "info": "The context of the document to combine with others",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "document_context",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RagPrompt"
        },
        "dragging": false,
        "id": "RagPrompt-vGvXR",
        "measured": {
          "height": 352,
          "width": 320
        },
        "position": {
          "x": 2263.7286498175868,
          "y": 1068.8140505472413
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SystemPrompt-cM1BX",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a system prompt that informs the AI assistant about available folders and documents.",
            "display_name": "System Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "document_context",
              "memory"
            ],
            "frozen": false,
            "icon": "terminal",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "System Prompt",
                "method": "format_system_prompt",
                "name": "system_prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema.message import Message\n\nSYSTEM_PROMPT = \"\"\" \nYou are a helpful assistant that can use tools to answer questions and perform tasks.\nInside input found title of documents or folders. Later your need use tools with this ids.\nIf name of folders or documents not available - do not use tools.\nIf extensions is empty - it is folder. This folder can has subfolders or files \nfrom user query.\n\nList of available folders and documents:\n{folders_and_documents}\n\"\"\"\n\n\nclass SystemPromptComponent(Component):\n    \"\"\"\n    Component that formats a system prompt with available folders and documents.\n    Creates a structured prompt that instructs an AI assistant about available documents and folders.\n    \"\"\"\n\n    display_name = \"System Prompt\"\n    description = \"Creates a system prompt that informs the AI assistant about available folders and documents.\"\n    icon = \"terminal\"\n    name = \"SystemPrompt\"\n\n    inputs = [\n        DataInput(\n            name=\"document_context\",\n            display_name=\"Folders and Documents\",\n            info=\"List of available folders and documents to include in the system prompt\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"System Prompt\",\n            name=\"system_prompt\",\n            method=\"format_system_prompt\",\n        ),\n    ]\n\n    def format_system_prompt(self) -> Message:\n        \"\"\"\n        Formats a system prompt with the provided folders and documents information.\n\n        Returns:\n            Message: A message containing the formatted system prompt\n        \"\"\"\n        # Get the document context\n        folders_and_documents = self.document_context.data.get(\"content\", [])\n\n        formated_content = \"\\n\".join(\n            f'Title: {str(item.get('title'))} id: {str(item.get('id'))} extension: {str(item.get('fileExst', ''))}' for item in folders_and_documents)\n\n        # Format the system prompt template with the document context\n        formatted_prompt = SYSTEM_PROMPT.format(\n            folders_and_documents=formated_content)\n\n        # Create a new message with the formatted prompt\n        # Preserve metadata from the document context message\n        system_prompt_msg = Message(\n            text=formatted_prompt,\n        )\n\n        return system_prompt_msg\n"
              },
              "document_context": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Folders and Documents",
                "dynamic": false,
                "info": "List of available folders and documents to include in the system prompt",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "document_context",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SystemPrompt"
        },
        "dragging": false,
        "id": "SystemPrompt-cM1BX",
        "measured": {
          "height": 314,
          "width": 320
        },
        "position": {
          "x": 486.14797003420523,
          "y": 2729.2104833754656
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GetFoldersContent-APjkO",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves folder content including files, subfolders, and metadata from DocSpace",
            "display_name": "Get Folder Content",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "asc_auth_key",
              "files_host"
            ],
            "frozen": false,
            "icon": "folder-open",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Folder Content",
                "method": "get_files_from_folders",
                "name": "folder_content",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asc_auth_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Auth key",
                "dynamic": false,
                "info": "Auth key to use",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "asc_auth_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "asc_auth_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import MessageInput, DataInput, MessageTextInput\nfrom langflow.io import Output\nfrom langflow.schema import Data\n\n\nclass GetFoldersContentComponent(Component):\n    \"\"\"Component for retrieving complete folder content from DocSpace via API.\"\"\"\n\n    display_name: str = \"Get Folder Content\"\n    description: str = \"Retrieves folder content including files, subfolders, and metadata from DocSpace\"\n    name: str = \"GetFoldersContent\"\n    icon = \"folder-open\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Folders and Files IDs\",\n            info=\"IDs of the folders and files to get\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"asc_auth_key\",\n            display_name=\"Auth key\",\n            info=\"Auth key to use\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"files_host\",\n            display_name=\"Files Service Host\",\n            info=\"Host URL for the files service\",\n            required=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            name=\"folder_content\",\n            display_name=\"Folder Content\",\n            method=\"get_files_from_folders\",\n        ),\n    ]\n\n    async def get_folder(self, session: aiohttp.ClientSession, folder_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Make an async API request to get folder information from DocSpace.\n\n        Args:\n            session: aiohttp client session\n            folder_id: ID of the folder to retrieve\n\n        Returns:\n            Dict containing the folder information including metadata and contents\n        \"\"\"\n        try:\n            headers = {\n                'Authorization': self.asc_auth_key,\n            }\n\n            files_host = self.files_host.get_text()\n            url = f'{files_host}/api/2.0/files/{folder_id}'\n\n            async with session.get(url, headers=headers, timeout=30) as response:\n                response.raise_for_status()\n                data = await response.json()\n                return data[\"response\"]\n\n        except Exception as e:\n            print(f\"Error getting folder {folder_id}: {str(e)}\")\n            return None\n\n    async def fetch_all_folders(self, folder_ids: List[str]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Fetch all folders concurrently using aiohttp for efficient retrieval.\n\n        Args:\n            folder_ids: List of folder IDs to fetch from DocSpace\n\n        Returns:\n            List of folder information dictionaries with complete metadata\n        \"\"\"\n        async with aiohttp.ClientSession() as session:\n            # Create tasks for all file fetches\n            tasks = [self.get_folder(session, folder_id)\n                     for folder_id in folder_ids]\n            # Wait for all tasks to complete (like Promise.all)\n            results = await asyncio.gather(*tasks)\n            # Filter out None results (failed requests)\n            return [r for r in results if r is not None]\n\n    async def get_files_from_folders(self) -> Data:\n        \"\"\"\n        Make concurrent API requests to retrieve folders from DocSpace and extract their files.\n        Processes the input folder IDs, fetches folder information, and extracts file metadata.\n\n        Returns:\n            Data object containing a list of file information dictionaries extracted from the folders\n        \"\"\"\n        try:\n            # Get folder IDs from input data\n            folders_data: List[str] = self.data.data.get(\n                \"folders\", [])\n\n            if not folders_data:\n                return Data(data={\"content\": []})\n\n            # Fetch all folders concurrently\n            folders_info = await self.fetch_all_folders(folders_data)\n\n            content = []\n\n            content.extend(folders_info[0].get('folders', []))\n            content.extend(folders_info[0].get('files', []))\n\n            return Data(data={\"content\": content})\n\n        except Exception as e:\n            return Data(data={\"content\": []})\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Folders and Files IDs",
                "dynamic": false,
                "info": "IDs of the folders and files to get",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "files_host": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Files Service Host",
                "dynamic": false,
                "info": "Host URL for the files service",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "files_host",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "GetFoldersContent"
        },
        "dragging": false,
        "id": "GetFoldersContent-APjkO",
        "measured": {
          "height": 377,
          "width": 320
        },
        "position": {
          "x": -315.040000863248,
          "y": 1889.2604876364394
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ToolCallingAgent-U12uF",
          "node": {
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "An agent designed to utilize various tools seamlessly within workflows.",
            "display_name": "Tool Calling Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "llm",
              "system_prompt",
              "chat_history"
            ],
            "frozen": false,
            "icon": "LangChain",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Agent",
                "hidden": true,
                "method": "build_agent",
                "name": "agent",
                "required_inputs": [],
                "selected": "AgentExecutor",
                "tool_mode": false,
                "types": [
                  "AgentExecutor"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "method": "message_response",
                "name": "response",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "chat_history": {
                "_input_type": "DataInput",
                "advanced": true,
                "display_name": "Chat Memory",
                "dynamic": false,
                "info": "This input stores the chat history, allowing the agent to remember previous conversations.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "chat_history",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import MessageTextInput\nfrom langflow.inputs.inputs import DataInput, HandleInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"An agent designed to utilize various tools seamlessly within workflows.\"\n    icon = \"LangChain\"\n    name = \"ToolCallingAgent\"\n\n    inputs = [\n        *LCToolsAgentComponent._base_inputs,\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"Language model that the agent utilizes to perform tasks effectively.\",\n        ),\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n        ),\n        DataInput(\n            name=\"chat_history\",\n            display_name=\"Chat Memory\",\n            is_list=True,\n            advanced=True,\n            info=\"This input stores the chat history, allowing the agent to remember previous conversations.\",\n        ),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        messages = [\n            (\"system\", \"{system_prompt}\"),\n            (\"placeholder\", \"{chat_history}\"),\n            (\"human\", \"{input}\"),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        self.validate_tool_names()\n        try:\n            return create_tool_calling_agent(self.llm, self.tools or [], prompt)\n        except NotImplementedError as e:\n            message = f\"{self.display_name} does not support tool calling. Please try using a compatible model.\"\n            raise NotImplementedError(message) from e\n\n    async def to_toolkit(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        toolkit = component_toolkit(component=self)\n        tools = toolkit.get_tools(callbacks=self.get_langchain_callbacks())\n        if hasattr(self, \"tools_metadata\"):\n            tools = toolkit.update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that the agent utilizes to perform tasks effectively.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "system_prompt": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "System Prompt",
                "dynamic": false,
                "info": "System prompt to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ToolCallingAgent"
        },
        "dragging": false,
        "id": "ToolCallingAgent-U12uF",
        "measured": {
          "height": 421,
          "width": 320
        },
        "position": {
          "x": 2564.2637685819727,
          "y": 2525.998632358814
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OnlyofficeDocspaceFolderListDocuments-6gGL6",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieve documents from the folder.",
            "display_name": "Folder Documents",
            "documentation": "",
            "edited": true,
            "field_order": [
              "asc_auth_key",
              "folder_id"
            ],
            "frozen": false,
            "icon": "code",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "hidden": null,
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Tool",
                "hidden": null,
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asc_auth_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Auth key",
                "dynamic": false,
                "info": "Auth key to use",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "asc_auth_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "asc_auth_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from urllib.parse import urljoin\nfrom langchain.tools import StructuredTool\nfrom langflow.custom.custom_component.component_with_cache import ComponentWithCache\nfrom langflow.inputs.inputs import MessageInput, DataInput, MessageTextInput, StrInput\nfrom langflow.field_typing import Tool\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.services.cache.utils import CacheMiss\nfrom langflow.template import Output\nfrom pydantic import BaseModel, Field\nimport requests\n\nclass OnlyofficeDocspaceListDocuments(ComponentWithCache):\n\tdisplay_name = \"Folder Documents\"\n\tdescription = \"Retrieve documents from the folder.\"\n\ticon = \"code\"\n\tname = \"OnlyofficeDocspaceFolderListDocuments\"\n\t\n\tinputs = [\n\t    MessageTextInput(\n            name=\"asc_auth_key\",\n            display_name=\"Auth key\",\n            info=\"Auth key to use\",\n            required=True,\n        ),\n\t\tStrInput(\n\t\t\tname=\"folder_id\",\n\t\t\tdisplay_name=\"Folder ID\",\n\t\t\tinfo=\"The ID of the folder to get content.\",\n\t\t),\n\t]\n\n\toutputs = [\n\t\tOutput(\n\t\t\tdisplay_name=\"Data\",\n\t\t\tname=\"api_run_model\",\n\t\t\tmethod=\"run_model\",\n\t\t),\n\t\tOutput(\n\t\t\tdisplay_name=\"Tool\",\n\t\t\tname=\"api_build_tool\",\n\t\t\tmethod=\"build_tool\",\n\t\t),\n\t]\n\n\tclass OnlyofficeDocspaceListDocumentsSchema(BaseModel):\n\t\tfolder_id: str = Field(..., description=\"The ID of the folder to get content.\")\n\n\n\tdef run_model(self) -> Data:\n\t\tres = self._list_documents()\n\t\treturn Data(data=res)\n\n\tdef build_tool(self) -> Tool:\n\t\treturn StructuredTool.from_function(\n\t\t\tname=\"onlyoffice_docspace_folder_documents\",\n\t\t\tdescription=\"Retrieve documents from the folder.\",\n\t\t\tfunc=self._list_documents,\n\t\t\targs_schema=self.OnlyofficeDocspaceListDocumentsSchema,\n\t\t)\n\n\tdef _list_documents(self, folder_id: str) -> dict:\n\t\turl = f'http://onlyoffice-files:5050/api/2.0/files/{folder_id}'\n\t\theaders = {\n\t\t\t\"Accept\": \"application/json\",\n\t\t\t\"Authorization\": f\"{self.asc_auth_key}\",\n\t\t}\n\t\tres = requests.request(\"GET\", url, headers=headers)\n\t\tres.raise_for_status()\n\t\treturn res.json()\n"
              },
              "folder_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Folder ID",
                "dynamic": false,
                "info": "The ID of the folder to get content.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "folder_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OnlyofficeDocspaceFolderListDocuments"
        },
        "dragging": false,
        "id": "OnlyofficeDocspaceFolderListDocuments-6gGL6",
        "measured": {
          "height": 360,
          "width": 320
        },
        "position": {
          "x": 2144.374585116905,
          "y": 1960.1993430454056
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TogetherAIModel-i6idC",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using TogetherAI LLMs.",
            "display_name": "TogetherAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "togetherai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "TogetherAI",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "TogetherAI API Key",
                "dynamic": false,
                "info": "The TogetherAI API Key to use for the TogetherAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "togetherai_api_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langchain_openai import ChatOpenAI\nfrom langchain_together import ChatTogether\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\n#from langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.base.models.togetherai_constants import TOGETHERAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass TogetherAIModelComponent(LCModelComponent):\n    display_name = \"TogetherAI\"\n    description = \"Generates text using TogetherAI LLMs.\"\n    icon = \"TogetherAI\"\n    name = \"TogetherAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=TOGETHERAI_MODEL_NAMES,\n            value=TOGETHERAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"togetherai_api_base\",\n            display_name=\"TogetherAI API Base\",\n            advanced=True,\n            info=\"The base URL of the TogetherAI API. \"\n            \"Defaults to https://api.together.xyz/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"TogetherAI API Key\",\n            info=\"The TogetherAI API Key to use for the TogetherAI model.\",\n            advanced=False,\n            value=\"TOGETHERAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to TogetherAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        togetherai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        togetherai_api_base = self.togetherai_api_base or \"https://api.together.xyz/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(togetherai_api_key).get_secret_value() if togetherai_api_key else None\n        output = ChatTogether(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=togetherai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an TogetherAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        # try:\n        #     from openai import BadRequestError\n        # except ImportError:\n        #     return None\n        # if isinstance(e, BadRequestError):\n        #     message = e.body.get(\"message\")\n        #     if message:\n        #         return message\n        return e\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
                  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to TogetherAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "togetherai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "TogetherAI API Base",
                "dynamic": false,
                "info": "The base URL of the TogetherAI API. Defaults to https://api.together.xyz/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "togetherai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TogetherAIModel"
        },
        "dragging": false,
        "id": "TogetherAIModel-i6idC",
        "measured": {
          "height": 656,
          "width": 320
        },
        "position": {
          "x": 564.1304623975395,
          "y": 1769.1370436482023
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RunFlow-PBB3K",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "beta": true,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a tool component from a Flow that takes all its inputs and runs it.  \n **Select a Flow to use the tool mode**",
            "display_name": "Run Flow",
            "documentation": "",
            "edited": false,
            "field_order": [
              "flow_name_selected",
              "session_id"
            ],
            "frozen": false,
            "icon": "Workflow",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Data Output",
                "hidden": true,
                "method": "data_output",
                "name": "flow_outputs_data",
                "required_inputs": [],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Dataframe Output",
                "hidden": true,
                "method": "dataframe_output",
                "name": "flow_outputs_dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Message Output",
                "method": "message_output",
                "name": "flow_outputs_message",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom loguru import logger\n\nfrom langflow.base.tools.run_flow import RunFlowBaseComponent\nfrom langflow.helpers.flow import run_flow\nfrom langflow.schema import dotdict\n\n\nclass RunFlowComponent(RunFlowBaseComponent):\n    display_name = \"Run Flow\"\n    description = (\n        \"Creates a tool component from a Flow that takes all its inputs and runs it. \"\n        \" \\n **Select a Flow to use the tool mode**\"\n    )\n    beta = True\n    name = \"RunFlow\"\n    icon = \"Workflow\"\n\n    inputs = RunFlowBaseComponent._base_inputs\n    outputs = RunFlowBaseComponent._base_outputs\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name_selected\":\n            build_config[\"flow_name_selected\"][\"options\"] = await self.get_flow_names()\n            missing_keys = [key for key in self.default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n            if field_value is not None:\n                try:\n                    graph = await self.get_graph(field_value)\n                    build_config = self.update_build_config_from_graph(build_config, graph)\n                except Exception as e:\n                    msg = f\"Error building graph for flow {field_value}\"\n                    logger.exception(msg)\n                    raise RuntimeError(msg) from e\n        return build_config\n\n    async def run_flow_with_tweaks(self):\n        tweaks: dict = {}\n\n        flow_name_selected = self._attributes.get(\"flow_name_selected\")\n        parsed_flow_tweak_data = self._attributes.get(\"flow_tweak_data\", {})\n        if not isinstance(parsed_flow_tweak_data, dict):\n            parsed_flow_tweak_data = parsed_flow_tweak_data.dict()\n\n        if parsed_flow_tweak_data != {}:\n            for field in parsed_flow_tweak_data:\n                if \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = parsed_flow_tweak_data[field]\n        else:\n            for field in self._attributes:\n                if field not in self.default_keys and \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = self._attributes[field]\n\n        return await run_flow(\n            inputs=None,\n            output_type=\"all\",\n            flow_id=None,\n            flow_name=flow_name_selected,\n            tweaks=tweaks,\n            user_id=str(self.user_id),\n            session_id=self.graph.session_id or self.session_id,\n        )\n"
              },
              "flow_name_selected": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Flow Name",
                "dynamic": false,
                "info": "The name of the flow to run.",
                "name": "flow_name_selected",
                "options": [],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Get context from files"
              },
              "session_id": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID to run the flow in.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": {
                  "data": {
                    "files": [],
                    "text": "",
                    "timestamp": "2025-03-04 09:26:02 UTC"
                  },
                  "default_value": "",
                  "text_key": "text"
                }
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RunFlow"
        },
        "dragging": false,
        "id": "RunFlow-PBB3K",
        "measured": {
          "height": 435,
          "width": 320
        },
        "position": {
          "x": 3417.205762801653,
          "y": 2495.7346929393643
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-TPR8t",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Use as a template to create your own component.",
            "display_name": "Custom Component",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "code",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "method": "build_output",
                "name": "output",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"This is a custom component Input\",\n            value=\"Hello, World!\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        data = Data(value=self.input_value)\n        self.status = data\n        return data\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Value",
                "dynamic": false,
                "info": "This is a custom component Input",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CustomComponent"
        },
        "dragging": false,
        "id": "CustomComponent-TPR8t",
        "measured": {
          "height": 250,
          "width": 320
        },
        "position": {
          "x": 2978.803693975776,
          "y": 2707.040089122709
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TogetherAIModel-YLhJ2",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using TogetherAI LLMs.",
            "display_name": "TogetherAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "togetherai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "TogetherAI",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "TogetherAI API Key",
                "dynamic": false,
                "info": "The TogetherAI API Key to use for the TogetherAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "togetherai_api_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langchain_openai import ChatOpenAI\nfrom langchain_together import ChatTogether\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\n#from langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.base.models.togetherai_constants import TOGETHERAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass TogetherAIModelComponent(LCModelComponent):\n    display_name = \"TogetherAI\"\n    description = \"Generates text using TogetherAI LLMs.\"\n    icon = \"TogetherAI\"\n    name = \"TogetherAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=TOGETHERAI_MODEL_NAMES,\n            value=TOGETHERAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"togetherai_api_base\",\n            display_name=\"TogetherAI API Base\",\n            advanced=True,\n            info=\"The base URL of the TogetherAI API. \"\n            \"Defaults to https://api.together.xyz/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"TogetherAI API Key\",\n            info=\"The TogetherAI API Key to use for the TogetherAI model.\",\n            advanced=False,\n            value=\"TOGETHERAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to TogetherAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        togetherai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        togetherai_api_base = self.togetherai_api_base or \"https://api.together.xyz/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(togetherai_api_key).get_secret_value() if togetherai_api_key else None\n        output = ChatTogether(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=togetherai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an TogetherAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        # try:\n        #     from openai import BadRequestError\n        # except ImportError:\n        #     return None\n        # if isinstance(e, BadRequestError):\n        #     message = e.body.get(\"message\")\n        #     if message:\n        #         return message\n        return e\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
                  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to TogetherAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "togetherai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "TogetherAI API Base",
                "dynamic": false,
                "info": "The base URL of the TogetherAI API. Defaults to https://api.together.xyz/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "togetherai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TogetherAIModel"
        },
        "dragging": false,
        "id": "TogetherAIModel-YLhJ2",
        "measured": {
          "height": 656,
          "width": 320
        },
        "position": {
          "x": 4326.020413133716,
          "y": 2352.1769138255377
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-4t5Zg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if not isinstance(self.input_value, Data | DataFrame | Message | str | list):\n            msg = f\"Expected Data or DataFrame or Message or str, got {type(self.input_value).__name__}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-4t5Zg",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 5056.621466515349,
          "y": 2352.415067052223
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "EnvExtractor-picCE",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extract environment variables for DocSpace services",
            "display_name": "Environment Variables Extractor",
            "documentation": "",
            "edited": false,
            "field_order": [],
            "frozen": false,
            "icon": "settings",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "API Service",
                "method": "get_api_host",
                "name": "api_host",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Files Service",
                "method": "get_files_host",
                "name": "files_host",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Qdrant Service",
                "method": "get_qdrant_host",
                "name": "qdrant_host",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Qdrant Port",
                "method": "get_qdrant_port",
                "name": "qdrant_port",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nfrom langflow.custom import Component\nfrom langflow.io import Output\nfrom langflow.schema import Message\n\n\nclass EnvExtractorComponent(Component):\n    \"\"\"Component for extracting environment variables.\"\"\"\n\n    display_name: str = \"Environment Variables Extractor\"\n    description: str = \"Extract environment variables for DocSpace services\"\n    name: str = \"EnvExtractor\"\n    icon = \"settings\"\n\n    outputs = [\n        Output(\n            name=\"api_host\",\n            display_name=\"API Service\",\n            method=\"get_api_host\",\n        ),\n        Output(\n            name=\"files_host\",\n            display_name=\"Files Service\",\n            method=\"get_files_host\",\n        ),\n        Output(\n            name=\"qdrant_host\",\n            display_name=\"Qdrant Service\",\n            method=\"get_qdrant_host\",\n        ),\n        Output(\n            name=\"qdrant_port\",\n            display_name=\"Qdrant Port\",\n            method=\"get_qdrant_port\",\n        ),\n    ]\n\n    def get_api_host(self) -> Message:\n        \"\"\"\n        Get the API service host from environment variables.\n\n        Returns:\n            Message object containing the API host URL\n        \"\"\"\n        try:\n            api_host = os.environ.get(\n                'HOST_API_SERVICE', 'http://onlyoffice-api:5050')\n            return Message(text=api_host)\n        except Exception as e:\n            raise ValueError(f\"Error getting API host: {str(e)}\")\n\n    def get_files_host(self) -> Message:\n        \"\"\"\n        Get the Files service host from environment variables.\n\n        Returns:\n            Message object containing the Files host URL\n        \"\"\"\n        try:\n            files_host = os.environ.get(\n                'HOST_FILES_SERVICE', 'http://onlyoffice-files:5050')\n            return Message(text=files_host)\n        except Exception as e:\n            raise ValueError(f\"Error getting Files host: {str(e)}\")\n\n    def get_qdrant_host(self) -> Message:\n        \"\"\"\n        Get the Qdrant service host from environment variables.\n\n        Returns:\n            Message object containing the Qdrant host URL\n        \"\"\"\n        try:\n            qdrant_host = os.environ.get(\n                'HOST_QDRANT_SERVICE', 'onlyoffice-qdrant')\n            return Message(text=qdrant_host)\n        except Exception as e:\n            raise ValueError(f\"Error getting Qdrant host: {str(e)}\")\n            \n    def get_qdrant_port(self) -> Message:\n        \"\"\"\n        Get the Qdrant service port from environment variables.\n\n        Returns:\n            Message object containing the Qdrant port\n        \"\"\"\n        try:\n            qdrant_port = os.environ.get(\n                'HOST_QDRANT_PORT', '6333')\n            return Message(text=qdrant_port)\n        except Exception as e:\n            raise ValueError(f\"Error getting Qdrant port: {str(e)}\")\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "EnvExtractor"
        },
        "id": "EnvExtractor-picCE",
        "measured": {
          "height": 311,
          "width": 320
        },
        "position": {
          "x": -960,
          "y": 2280
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OnlyofficeDocspaceFolderListDocuments-Y61FS",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieve file info.",
            "display_name": "Folder Documents",
            "documentation": "",
            "edited": true,
            "field_order": [
              "asc_auth_key",
              "file_id"
            ],
            "frozen": false,
            "icon": "code",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "hidden": null,
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Tool",
                "hidden": null,
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asc_auth_key": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Auth key",
                "dynamic": false,
                "info": "Auth key to use",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": true,
                "name": "asc_auth_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "asc_auth_key"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from urllib.parse import urljoin\nfrom langchain.tools import StructuredTool\nfrom langflow.custom.custom_component.component_with_cache import ComponentWithCache\nfrom langflow.inputs.inputs import MessageInput, DataInput, MessageTextInput, StrInput\nfrom langflow.field_typing import Tool\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.services.cache.utils import CacheMiss\nfrom langflow.template import Output\nfrom pydantic import BaseModel, Field\nimport requests\n\nclass OnlyofficeDocspaceFileInfo(ComponentWithCache):\n\tdisplay_name = \"Folder Documents\"\n\tdescription = \"Retrieve file info.\"\n\ticon = \"code\"\n\tname = \"OnlyofficeDocspaceFolderListDocuments\"\n\t\n\tinputs = [\n\t    MessageTextInput(\n            name=\"asc_auth_key\",\n            display_name=\"Auth key\",\n            info=\"Auth key to use\",\n            required=True,\n        ),\n\t\tStrInput(\n\t\t\tname=\"file_id\",\n\t\t\tdisplay_name=\"Folder ID\",\n\t\t\tinfo=\"The ID of file to get content.\",\n\t\t),\n\t]\n\n\toutputs = [\n\t\tOutput(\n\t\t\tdisplay_name=\"Data\",\n\t\t\tname=\"api_run_model\",\n\t\t\tmethod=\"run_model\",\n\t\t),\n\t\tOutput(\n\t\t\tdisplay_name=\"Tool\",\n\t\t\tname=\"api_build_tool\",\n\t\t\tmethod=\"build_tool\",\n\t\t),\n\t]\n\n\tclass OnlyofficeDocspaceListDocumentsSchema(BaseModel):\n\t\tfolder_id: str = Field(..., description=\"The ID of the file to get content.\")\n\n\n\tdef run_model(self) -> Data:\n\t\tres = self._list_documents()\n\t\treturn Data(data=res)\n\n\tdef build_tool(self) -> Tool:\n\t\treturn StructuredTool.from_function(\n\t\t\tname=\"onlyoffice_docspace_file_document\",\n\t\t\tdescription=\"Retrieve file by id.\",\n\t\t\tfunc=self._list_documents,\n\t\t\targs_schema=self.OnlyofficeDocspaceListDocumentsSchema,\n\t\t)\n\n\tdef _list_documents(self, file_id: str) -> dict:\n\t\turl = f'http://onlyoffice-files:5050/api/2.0/files/file/{file_id}'\n\t\theaders = {\n\t\t\t\"Accept\": \"application/json\",\n\t\t\t\"Authorization\": f\"{self.asc_auth_key}\",\n\t\t}\n\t\tres = requests.request(\"GET\", url, headers=headers)\n\t\tres.raise_for_status()\n\t\treturn res.json()\n"
              },
              "file_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Folder ID",
                "dynamic": false,
                "info": "The ID of file to get content.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "file_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OnlyofficeDocspaceFolderListDocuments"
        },
        "dragging": false,
        "id": "OnlyofficeDocspaceFolderListDocuments-Y61FS",
        "measured": {
          "height": 360,
          "width": 320
        },
        "position": {
          "x": 2558.6680831649155,
          "y": 1919.2708566439815
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Memory-dsE8e",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Chat Memory",
            "documentation": "",
            "edited": false,
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "frozen": false,
            "icon": "message-square-more",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "method": "retrieve_messages",
                "name": "messages",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "retrieve_messages_as_text",
                "name": "messages_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs import HandleInput\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import aget_messages\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n    ]\n\n    async def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = await aget_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n"
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              }
            },
            "tool_mode": false
          },
          "type": "Memory"
        },
        "dragging": false,
        "id": "Memory-dsE8e",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": -121.78966076071609,
          "y": 2778.768587763562
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RagPrompt-pvny9",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Creates a structured RAG prompt with document context for retrieval-augmented generation.",
            "display_name": "RAG Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "document_context",
              "memory"
            ],
            "frozen": false,
            "icon": "file-text",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "RAG Prompt",
                "method": "format_rag_prompt",
                "name": "rag_prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema.message import Message\n\nRAG_PROMPT = \"\"\" \nDOCUMENTS:\n{document}\n\nINSTRUCTIONS:\nAnswer the users QUESTION using the DOCUMENTS text above.\nKeep your answer ground in the facts of the DOCUMENTS.\nIf the DOCUMENTS doesn't contain the facts to answer the QUESTION return 'Not known'\n\"\"\"\n\n\nclass RagPromptComponent(Component):\n    \"\"\"\n    Component that formats a RAG prompt with document context.\n    Creates a structured prompt for retrieval-augmented generation.\n    \"\"\"\n\n    display_name = \"RAG Prompt\"\n    description = \"Creates a structured RAG prompt with document context for retrieval-augmented generation.\"\n    icon = \"file-text\"\n    name = \"RagPrompt\"\n\n    inputs = [\n        MessageInput(\n            name=\"document_context\",\n            display_name=\"Document context\",\n            info=\"The context of the document to combine with others\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"RAG Prompt\",\n            name=\"rag_prompt\",\n            method=\"format_rag_prompt\",\n        ),\n    ]\n\n    def format_rag_prompt(self) -> Message:\n        \"\"\"\n        Formats a RAG prompt with the provided document context.\n\n        Returns:\n            Message: A message containing the formatted RAG prompt\n        \"\"\"\n        # Get the document context\n        doc_msg = self.document_context\n        document_content = doc_msg.get_text() if doc_msg else \"\"\n\n        # Format the RAG prompt template with the document context\n        formatted_prompt = RAG_PROMPT.format(document=document_content)\n\n        # Create a new message with the formatted prompt\n        # Preserve metadata from the document context message\n        rag_prompt_msg = Message(\n            text=formatted_prompt,\n            sender=doc_msg.sender if doc_msg else None,\n            sender_name=doc_msg.sender_name if doc_msg else None,\n            session_id=doc_msg.session_id if doc_msg else None,\n            flow_id=doc_msg.flow_id if doc_msg else None,\n        )\n\n        return rag_prompt_msg\n"
              },
              "document_context": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Document context",
                "dynamic": false,
                "info": "The context of the document to combine with others",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "document_context",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RagPrompt"
        },
        "dragging": false,
        "id": "RagPrompt-pvny9",
        "measured": {
          "height": 352,
          "width": 320
        },
        "position": {
          "x": 3864.2955039163085,
          "y": 2685.019221942129
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "InputParser-iyYS7",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Parse an input and return a parsed data object.",
            "display_name": "Parse input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.1.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed data",
                "method": "parse_input",
                "name": "parsed_data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\n\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import MessageInput\nfrom langflow.io import Output\nfrom langflow.schema import Data, Message\n\n\nclass InputParserComponent(Component):\n    display_name: str = \"Parse input\"\n    description: str = \"Parse an input and return a parsed data object.\"\n    name: str = \"InputParser\"\n    icon = \"braces\"\n\n    inputs = [\n        MessageInput(\n            name=\"input\",\n            display_name=\"Input\",\n            info=\"User input to parse\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Parsed data\",\n               name=\"parsed_data\", method=\"parse_input\"),\n    ]\n\n    def parse_input(self) -> Data:\n        \"\"\"Parse input text to extract references.\n\n        References can be in the following formats:\n        - @123 (file ID)\n        - @folder-123 (folder ID)\n        - References can appear anywhere in the text\n\n        Returns:\n            Data object with extracted references and text\n        \"\"\"\n        try:\n            # Get text from input Message object\n            input_message: Message = self.input\n\n            text = input_message.get_text()\n            if not isinstance(text, str) or not text:\n                return Data(data={})\n\n            # Define regex patterns for file and folder references\n            file_pattern = r'@(\\d+)'  # Matches @123 (file ID)\n            folder_pattern = r'@folder-(\\d+)'  # Matches @folder-123 (folder ID)\n            \n            # Extract all references\n            file_refs = re.findall(file_pattern, text)\n            folder_refs = re.findall(folder_pattern, text)\n            \n            # Combine all references\n            references = file_refs + [f\"folder-{ref}\" for ref in folder_refs]\n            \n            # Remove references from text if they are at the beginning\n            # This maintains backward compatibility with the old format\n            cleaned_text = text\n            parts = text.split(' ', 1)\n            if parts[0].startswith('@'):\n                cleaned_text = parts[1] if len(parts) > 1 else ''\n            \n            result = {\n                \"references\": references,\n                \"text\": cleaned_text,\n                \"original_text\": text\n            }\n\n            return Data(data=result)\n\n        except Exception as e:\n            raise Exception(f\"Error parsing input: {str(e)}\")\n"
              },
              "input": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "User input to parse",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "InputParser"
        },
        "dragging": false,
        "id": "InputParser-iyYS7",
        "measured": {
          "height": 250,
          "width": 320
        },
        "position": {
          "x": -243.84494902273738,
          "y": 1091.6570562038396
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 228.8064967573867,
      "y": 33.5997151007341,
      "zoom": 0.18010146442530806
    }
  },
  "description": "Chain the Words, Master Language!",
  "endpoint_name": null,
  "folder_id": "74b09011-dc81-4b37-aa1a-d3f9e959985c",
  "gradient": null,
  "icon": null,
  "icon_bg_color": null,
  "id": "b68300a9-8358-4a48-9a9c-377d48ad8792",
  "is_component": false,
  "locked": false,
  "name": "DocSpace chat",
  "tags": null,
  "updated_at": "2025-03-13T04:34:05+00:00",
  "user_id": "31095b14-2cef-4f27-af10-1bfcfc85abba",
  "webhook": false
}